{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for examining how HMM performs under repeated recalibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys, glob\n",
    "[sys.path.append(f) for f in glob.glob('../utils/*')]\n",
    "from plotting_utils import figSize\n",
    "from hmm import HMMRecalibration\n",
    "import hmm_utils\n",
    "import simulation_utils \n",
    "from simulation import simulateBCIFitts\n",
    "import stabilizer_utils\n",
    "from stabilizer_utils import Stabilizer\n",
    "from RTI_utils import RTI\n",
    "\n",
    "# for a reproducible result\n",
    "np.random.seed(1)\n",
    "\n",
    "fig_path    = '/home/users/ghwilson/projects/nonstationarities/figures/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define an initial decoder and initial neural tuning properties (mean firing rates and preferred directions).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_MultiSessionStretch(base_opts, hmm = None, ss_opts = None, rti = None):\n",
    "    \n",
    "    cfg_dict   = dict()\n",
    "    order_dict = {'norecal_cfg' : 0, 'supervised_cfg' : 1}\n",
    "    cfg_dict['supervised_cfg'] = simulation_utils.initializeBCI(base_opts)\n",
    "    cfg_dict['norecal_cfg']    = simulation_utils.initializeBCI(base_opts)\n",
    "    \n",
    "    if hmm is not None:\n",
    "        cfg_dict['hmm_cfg']   = simulation_utils.initializeBCI(base_opts)\n",
    "        order_dict['hmm_cfg'] = len(order_dict.keys())\n",
    "        \n",
    "    if ss_opts is not None:\n",
    "        cfg_dict['ss_cfg'], ss_decoder_dict, stabilizer = simulation_utils.initializeBCI({**base_opts, **ss_opts})\n",
    "        cfg_dict['ss_cfg']['neuralTuning'][:, 0] = 0\n",
    "        order_dict['ss_cfg'] = len(order_dict.keys())\n",
    "        \n",
    "    if rti is not None:\n",
    "        cfg_dict['rti_cfg']   = simulation_utils.initializeBCI(base_opts)\n",
    "        order_dict['rti_cfg'] = len(order_dict.keys())\n",
    "\n",
    "    session_scores = np.zeros((base_opts['n_sessions'] + 1, len(cfg_dict.keys())))\n",
    "        \n",
    "    # Day 0 performance:\n",
    "    D_dict = dict()\n",
    "    for key, cfg in cfg_dict.items():\n",
    "        D_key         = key.split('cfg')[0] + 'D'\n",
    "        D_dict[D_key] = np.copy(cfg_dict[key]['D'])\n",
    "        \n",
    "    #ss_cfg['D'][:, 0]   = ss_cfg['D'][:,0] / np.linalg.norm(ss_cfg['D'][1:, :][:, 0]) / np.linalg.norm(ss_tuning[:, 1])\n",
    "    #ss_cfg['D'][:, 1]   = ss_cfg['D'][:,1] / np.linalg.norm(ss_cfg['D'][1:, :][:, 1]) / np.linalg.norm(ss_tuning[:, 2])   \n",
    "        \n",
    "    for i, (key, value) in enumerate(cfg_dict.items()):\n",
    "        session_scores[0, order_dict[key]] = np.mean(simulateBCIFitts(value)['ttt'])\n",
    "\n",
    "    \n",
    "    for i in range(base_opts['n_sessions']):\n",
    "        for j in range(base_opts['days_between'] + 1):\n",
    "            for key, cfg in cfg_dict.items():\n",
    "                # introduce daily nonstationarities between recorded sessions\n",
    "                cfg['neuralTuning'] = simulation_utils.simulateTuningShift(cfg['neuralTuning'], n_stable = base_opts['n_stable'], PD_shrinkage = base_opts['shrinkage'], \n",
    "                                                                  mean_shift = 0, renormalize = simulation_utils.sampleSNR())  \n",
    "        \n",
    "        # No recalibration:\n",
    "        D_dict['norecal_D'][:, 0] = D_dict['norecal_D'][:,0] / np.linalg.norm(D_dict['norecal_D'][1:, :][:, 0]) / np.linalg.norm(cfg_dict['norecal_cfg']['neuralTuning'][:, 1])\n",
    "        D_dict['norecal_D'][:, 1] = D_dict['norecal_D'][:,1] / np.linalg.norm(D_dict['norecal_D'][1:, :][:, 1]) / np.linalg.norm(cfg_dict['norecal_cfg']['neuralTuning'][:, 2])        \n",
    "\n",
    "        cfg_dict['norecal_cfg']['D']    = D_dict['norecal_D']\n",
    "        cfg_dict['norecal_cfg']['beta'] = simulation_utils.gainSweep(cfg_dict['norecal_cfg'], possibleGain = base_opts['possibleGain'])\n",
    "        \n",
    "        idx                          = order_dict['norecal_cfg']\n",
    "        session_scores[i+1, idx] = np.mean(simulateBCIFitts(cfg_dict['norecal_cfg'])['ttt'])\n",
    "        \n",
    "        # supervised: \n",
    "        cfg_dict['supervised_cfg']['D'] = simulation_utils.simulate_OpenLoopRecalibration(cfg_dict['supervised_cfg'], nSteps = 10000)\n",
    "        cfg_dict['supervised_cfg']['D'] = simulation_utils.simulate_ClosedLoopRecalibration(cfg_dict['supervised_cfg'])\n",
    "        idx                             = order_dict['supervised_cfg']\n",
    "        \n",
    "        cfg_dict['supervised_cfg']['beta'] = simulation_utils.gainSweep(cfg_dict['supervised_cfg'], \n",
    "                                                                       possibleGain = base_opts['possibleGain'])\n",
    "        \n",
    "        session_scores[i+1, idx]        = np.mean(simulateBCIFitts(cfg_dict['supervised_cfg'])['ttt'])\n",
    "        \n",
    "        # HMM recalibration (repeated):   \n",
    "        if hmm is not None:\n",
    "            cfg_dict['hmm_cfg']['D']    = simulation_utils.simulate_HMMRecalibration(cfg_dict['hmm_cfg'], hmm)\n",
    "            cfg_dict['hmm_cfg']['beta'] = simulation_utils.gainSweep(cfg_dict['hmm_cfg'], possibleGain = base_opts['possibleGain'])\n",
    "            idx                         = order_dict['hmm_cfg']\n",
    "            session_scores[i+1, idx]    = np.mean(simulateBCIFitts(cfg_dict['hmm_cfg'])['ttt'])         \n",
    "        \n",
    "        # stabilizer:\n",
    "        if ss_opts is not None:\n",
    "            cfg_dict['ss_cfg']['D'] = simulation_utils.simulate_LatentClosedLoopRecalibration(cfg_dict['ss_cfg'], ss_decoder_dict, \n",
    "                                                                                              stabilizer, ss_opts, daisy_chain = True)\n",
    "            cfg_dict['ss_cfg']['beta'] = simulation_utils.gainSweep(cfg_dict['ss_cfg'], possibleGain = base_opts['possibleGain'])\n",
    "            \n",
    "            idx                      = order_dict['ss_cfg']\n",
    "            session_scores[i+1, idx] = np.mean(simulateBCIFitts(cfg_dict['ss_cfg'])['ttt'])\n",
    "    \n",
    "        if rti is not None:\n",
    "            cfg_dict['rti_cfg']['D']    = simulation_utils.simulate_RTIRecalibration(cfg_dict['rti_cfg'], rti)\n",
    "            cfg_dict['rti_cfg']['beta'] = simulation_utils.gainSweep(cfg_dict['rti_cfg'], possibleGain = base_opts['possibleGain'])\n",
    "            idx                         = order_dict['rti_cfg']\n",
    "            session_scores[i+1, idx]    = np.mean(simulateBCIFitts(cfg_dict['rti_cfg'])['ttt']) \n",
    "            \n",
    "\n",
    "    return session_scores\n",
    "    \n",
    "    \n",
    "#TODO:\n",
    "# - modify tuning to remove means (thats whats breaking subspace realignment here)\n",
    "# - modify so each method gets its own initial tuning setup on day 0 and its own tuning shift \n",
    "#    - this will let you keep the independent samples t test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 45.8min\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed: 46.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed: 46.1min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed: 46.1min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed: 46.3min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed: 46.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 46.8min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 47.3min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed: 47.4min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed: 47.4min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed: 48.5min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 49.1min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed: 50.0min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 50.1min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 50.5min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed: 50.6min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed: 50.7min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed: 54.0min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 91.5min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed: 91.5min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed: 91.5min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 91.6min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 91.8min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed: 92.3min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed: 92.9min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 94.3min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed: 94.4min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed: 96.3min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed: 96.9min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed: 97.1min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 97.8min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 97.8min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed: 98.0min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed: 101.3min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 102.2min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed: 102.8min\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed: 103.2min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed: 110.4min\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# general settings:\n",
    "reps  = 100   # how many times to repeat the repeated nonstationarities simulation\n",
    "\n",
    "\n",
    "base_opts = dict()\n",
    "base_opts['alpha']          = 0.94 # amount of exponential smoothing (0.9 to 0.96 are reasonable)\n",
    "base_opts['delT']           = 0.02 # define the time step (20 ms)\n",
    "base_opts['nDelaySteps']    = 10   # define the simulated user's visual feedback delay (200 ms)\n",
    "base_opts['nSimSteps']      = 20000\n",
    "base_opts['nUnits']         = 192\n",
    "base_opts['SNR']            = 0.5\n",
    "base_opts['possibleGain']   = np.linspace(0.1,2.5,10)\n",
    "base_opts['center_means']   = False\n",
    "base_opts['nTrainingSteps'] = 10000\n",
    "\n",
    "\n",
    "base_opts['n_sessions']   = 60   # number of sessions to simulate \n",
    "base_opts['days_between'] = 0    # days between session days\n",
    "base_opts['shrinkage']    = 0.91  # relative tuning in subspace per new day\n",
    "base_opts['n_stable']     = 0\n",
    "\n",
    "# stabilizer settings:\n",
    "ss_opts                 = dict()\n",
    "ss_opts['B']            = 100\n",
    "ss_opts['thresh']       = 0.05\n",
    "ss_opts['n_components'] = 2\n",
    "ss_opts['model_type']   = 'PCA'\n",
    "\n",
    "# HMM settings:\n",
    "vmKappa    = 2              # Precision parameter for the von mises distribution\n",
    "probThresh = 'probWeighted' # todo: implement\n",
    "gridSize   = 20\n",
    "stayProb   = 0.999\n",
    "adjustKappa = lambda x: 1 / (1 + np.exp(-1 * (x - 0.) * 32.))\n",
    "\n",
    "# RTI settings:\n",
    "look_back = 240\n",
    "min_dist  = 0\n",
    "min_time  = 30\n",
    "\n",
    "\n",
    "#-----------------------------------------\n",
    "session_scores          = np.zeros((reps, base_opts['n_sessions'] + 1, 4)) \n",
    "\n",
    "rti                     = RTI(look_back, min_dist, min_time)\n",
    "\n",
    "targLocs                = hmm_utils.generateTargetGrid(gridSize = gridSize)\n",
    "stateTrans, pStateStart = hmm_utils.generateTransitionMatrix(gridSize = gridSize, stayProb = stayProb)\n",
    "hmm                     = HMMRecalibration(stateTrans, targLocs, pStateStart, vmKappa, adjustKappa = adjustKappa)\n",
    "\n",
    "\n",
    "args           = [[base_opts, hmm, ss_opts, rti]] * reps\n",
    "rep_data       = Parallel(n_jobs= -1, verbose = 11)(delayed(simulate_MultiSessionStretch)(*x) for x in args)\n",
    "session_scores = np.dstack(rep_data).swapaxes(2, 0).swapaxes(1, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figSize(5, 15)\n",
    "from lineplots import plotsd\n",
    "import seaborn as sns \n",
    "figSize(5, 15)\n",
    "\n",
    "labels = ['None', 'Supervised', 'HMM', 'subspace', 'RTI']\n",
    "colors = ['r', 'g', 'b', 'purple', 'orange']\n",
    "\n",
    "#labels = ['None', 'Supervised', 'subspace']\n",
    "#colors = ['r', 'g', 'b']\n",
    "\n",
    "days     = np.linspace(0, (base_opts['days_between'] + 1) * base_opts['n_sessions'], base_opts['n_sessions'] + 1)\n",
    "fig, axs = plt.subplots(1, 2, gridspec_kw={'width_ratios': [2, 1]})\n",
    "\n",
    "# plot data across time\n",
    "plt.axes(axs[0])\n",
    "for i, label in enumerate(labels):\n",
    "    plotsd(data = session_scores[:, :, i], time_bins = days, color = colors[i], toggleSE = False)\n",
    "\n",
    "axs[0].legend(labels, loc = 'upper left')\n",
    "axs[0].set_title('Recalibration performance across time (alpha = ' + str(base_opts['shrinkage']) + ')')\n",
    "axs[0].set_xlabel('Days')\n",
    "axs[0].set_ylabel('Time to target (sec)')\n",
    "axs[0].spines['right'].set_visible(False)\n",
    "axs[0].spines['top'].set_visible(False)\n",
    "axs[0].set_ylim([0, 11])\n",
    "\n",
    "# and now the results on final day\n",
    "plt_data = [session_scores[:, -1, i].flatten() for i in range(len(labels))]\n",
    "cmap     = dict(zip(np.arange(len(labels)), colors))\n",
    "sns.stripplot(data = plt_data, palette = cmap, ax = axs[1])\n",
    "\n",
    "sns.boxplot(medianprops={'ls': '-', 'lw': 2, 'alpha' : 0.6}, whiskerprops={'visible': False},\n",
    "            zorder=1, data=plt_data, showfliers=False, showbox=False, showcaps=False, ax=axs[1])\n",
    "\n",
    "for i, line in enumerate(axs[1].get_lines()):\n",
    "    line.set_color(cmap[np.floor(i / len(colors))])\n",
    "\n",
    "axs[1].spines['right'].set_visible(False)\n",
    "axs[1].spines['top'].set_visible(False)\n",
    "axs[1].spines['left'].set_visible(False)\n",
    "axs[1].spines['right'].set_visible(False)\n",
    "axs[1].set_yticks([])\n",
    "axs[1].set_xticklabels(labels, rotation = 45)\n",
    "axs[1].set_ylim([0, 11])\n",
    "\n",
    "\n",
    "plt.savefig(fig_path + 'simulator/repeated_recal', format = 'pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labels)):\n",
    "        if j > i:\n",
    "            print('{} and {}: \\n'.format(labels[i], labels[j]), scipy.stats.ranksums(plt_data[i], plt_data[j]) )\n",
    "            print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 31, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
