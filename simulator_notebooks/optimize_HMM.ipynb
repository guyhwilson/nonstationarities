{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for determining how to adjust VonMises dispersion parameter in cursor probabilistic model based on proximity to target.\n",
    "\n",
    "We'll use a logistic function (as seen below) with parametrized midpoint and steepness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils/plotting/')\n",
    "sys.path.append('../utils/recalibration/')\n",
    "sys.path.append('../utils/simulation/')\n",
    "from plotting_utils import figSize\n",
    "from hmm import HMMRecalibration\n",
    "from simulation import simulateBCIFitts\n",
    "import simulation_utils\n",
    "\n",
    "# for a reproducible result\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Define an initial decoder and initial neural tuning properties (mean firing rates and preferred directions)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "nUnits         = 192\n",
    "SNR            = 0.5\n",
    "nTrainingSteps = 10000\n",
    "\n",
    "initialTuning          = simulation_utils.generateUnits(n_units = nUnits, SNR = SNR)\n",
    "calNeural, calVelocity = simulation_utils.simulateUnitActivity(initialTuning, noise = 0.3, nSteps = nTrainingSteps)\n",
    "lr                     = LinearRegression(fit_intercept = True).fit(calNeural, calVelocity)\n",
    "D                      = np.hstack([lr.intercept_[:, np.newaxis], lr.coef_]).T\n",
    "\n",
    "# Normalize the gain of this decoder so that it will output vectors with a magnitude of 1 when the encoded velocity has a magnitude of 1. \n",
    "D[:, 0] = D[:,0] / np.linalg.norm(D[1:, :][:, 0]) / np.linalg.norm(initialTuning[:, 1])\n",
    "D[:, 1] = D[:,1] / np.linalg.norm(D[1:, :][:, 1]) / np.linalg.norm(initialTuning[:, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the amount of exponential smoothing used in the decoder (alpha). Values between 0.9 and 0.96 are pretty reasonable. We then do a sweep for beta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../utils/simulation/simulation.py:193: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float64, 2d, A), array(float64, 2d, C))\n",
      "  simAct  = getNeuralTuning(currControl, decode_params)\n",
      "../utils/simulation/simulation.py:196: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float64, 2d, A), array(float64, 2d, C))\n",
      "  rawDecVec = getDecodedControl(simAct, decode_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "Using gain value beta =  0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "cfg = dict()\n",
    "cfg['neuralTuning'] = initialTuning\n",
    "cfg['D']            = D\n",
    "cfg['alpha']        = 0.94 # amount of exponential smoothing (0.9 to 0.96 are reasonable)\n",
    "cfg['delT']         = 0.02 # define the time step (20 ms)\n",
    "cfg['nDelaySteps']  = 10   # define the simulated user's visual feedback delay (200 ms)\n",
    "cfg['nSimSteps']    = 10000\n",
    "\n",
    "possibleGain = np.linspace(0.1,2.5,10)\n",
    "cfg['beta']  = simulation_utils.gainSweep(cfg, possibleGain, verbose = True)\n",
    "\n",
    "print('Using gain value beta = ', cfg['beta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now simulate nonstationarity and identify optimal HMM parameters for recalibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hmm_utils\n",
    "import copy\n",
    "\n",
    "def simulate_HMM(args, cfg, n_sessions, days_between, shrinkage):\n",
    "    \n",
    "    adjustKappa             = lambda x: 1 / (1 + np.exp(-1 * (x - args['inflection']) * args['exp']))\n",
    "    targLocs                = hmm_utils.generateTargetGrid(gridSize = args['gridSize'])\n",
    "    stateTrans, pStateStart = hmm_utils.generateTransitionMatrix(gridSize = args['gridSize'], stayProb = args['stayProb'])\n",
    "\n",
    "    hmm = HMMRecalibration(stateTrans, targLocs, pStateStart, args['kappa'], adjustKappa = adjustKappa)\n",
    "\n",
    "    session_scores = np.zeros((n_sessions + 1))\n",
    "    \n",
    "    # Day 0 performance:\n",
    "    D_HMM     = np.copy(cfg['D'])\n",
    "    tuning    = np.copy(cfg['neuralTuning'])\n",
    "    \n",
    "    norecal_cfg = copy.deepcopy(cfg)\n",
    "    hmminit_cfg = copy.deepcopy(cfg)\n",
    "    hmmrep_cfg = copy.deepcopy(cfg)\n",
    "    \n",
    "    ttt     = simulateBCIFitts(cfg)['ttt']\n",
    "    session_scores[0] = np.mean(ttt)\n",
    "    \n",
    "    for i in range(n_sessions):\n",
    "        for j in range(days_between + 1):\n",
    "            # introduce daily nonstationarities between recorded sessions\n",
    "            tuning = simulation_utils.simulateTuningShift(tuning, PD_shrinkage = shrinkage, \n",
    "                                                          mean_shift = 0, renormalize = None)  \n",
    "        \n",
    "        norecal_cfg['neuralTuning'] = tuning\n",
    "        hmminit_cfg['neuralTuning'] = tuning\n",
    "        hmmrep_cfg['neuralTuning'] = tuning\n",
    "    \n",
    "\n",
    "        # HMM recalibration (repeated):\n",
    "        results_hmmrep          = simulateBCIFitts(hmmrep_cfg) \n",
    "        targStates, pTargState  = hmm.viterbi_search(results_hmmrep['rawDecTraj'], results_hmmrep['posTraj'])\n",
    "\n",
    "        inferredTargLoc  = targLocs[targStates.astype('int').flatten(),:]\n",
    "        inferredPosErr   = inferredTargLoc - results_hmmrep['posTraj']\n",
    "        inferredTargDist = np.linalg.norm(inferredPosErr, axis = 1)\n",
    "        neural           = results_hmmrep['neuralTraj']\n",
    "\n",
    "        D_HMM            = np.linalg.lstsq(np.hstack([np.ones((neural.shape[0], 1)), neural]), inferredPosErr, rcond = -1)[0]  # update previous decoder\n",
    "        decVec_new       = np.hstack([np.ones((neural.shape[0], 1)), neural]).dot(D_HMM)\n",
    "\n",
    "        inferredTargDir  = inferredPosErr / inferredTargDist[:, np.newaxis]\n",
    "        farIdx           = np.where(inferredTargDist > 0.4)[0]\n",
    "        projVec          = np.sum(np.multiply(decVec_new[farIdx, :], inferredTargDir[farIdx, :]), axis = 1)\n",
    "        D_HMM           /= np.mean(projVec)\n",
    "        \n",
    "        \n",
    "        hmmrep_cfg['D']          = D_HMM\n",
    "        ttt_RepeatedRecal        = simulateBCIFitts(hmmrep_cfg)['ttt'] #Simulate BCI performance with the HMM-recalibrated decoder\n",
    "        session_scores[i+1]  = np.mean(ttt_RepeatedRecal)\n",
    "        \n",
    "    return session_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:  4.0min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-02afa1d1a574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#--------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0msession_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulate_HMM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.89\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/software/user/open/python/3.6.1/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/software/user/open/python/3.6.1/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sys.path.append('../utils/preprocessing/')\n",
    "import sweep_utils\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "# general settings:\n",
    "nSimSteps  = 10000\n",
    "\n",
    "# HMM settings:\n",
    "base_opts               = dict()\n",
    "base_opts['gridSize']   = 20\n",
    "base_opts['probThresh'] = 'probWeighted'\n",
    "base_opts['stayProb']   = 0.9999\n",
    "\n",
    "\n",
    "# grid search settings:\n",
    "sweep_opts = dict()\n",
    "sweep_opts['inflection'] = np.linspace(0, 0.5, 21)\n",
    "sweep_opts['exp']        = np.linspace(1, 40, 11)\n",
    "sweep_opts['kappa']      = [0.5, 1, 2, 4, 8]\n",
    "           \n",
    "args = sweep_utils.generateArgs(sweep_opts, base_opts)\n",
    "\n",
    "           \n",
    "\n",
    "#--------------------------------------------------\n",
    "session_scores = Parallel(n_jobs= -1, verbose = 11)(delayed(simulate_HMM)(*[x,cfg, 10, 1, 0.89 ]) for x in args)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figSize(10, 24)\n",
    "\n",
    "argx, argy = np.unravel_index(np.argmin(sweep_scores), sweep_scores.shape)\n",
    "print('Best inflection: ', inflection_sweep[argx])\n",
    "print('Best exponent: ', exp_sweep[argy])\n",
    "\n",
    "plt.imshow(sweep_scores.T, aspect = 'auto')\n",
    "plt.xticks(np.arange(len(inflection_sweep)), np.round(inflection_sweep, 2))\n",
    "plt.yticks(np.arange(len(exp_sweep)), np.round(exp_sweep, 2))\n",
    "plt.colorbar(label = 'Time to target (sec)')\n",
    "#plt.clim([0, 2])\n",
    "plt.xlabel('Inflection offset')\n",
    "plt.ylabel('Exponent')\n",
    "plt.title('Average time-to-target for different kappa adjustment parameters', fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
