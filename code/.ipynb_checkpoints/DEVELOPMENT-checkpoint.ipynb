{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "[sys.path.append(f) for f in glob.glob('utils/*')]\n",
    "from preprocess import DataStruct\n",
    "from firingrate import raster2FR\n",
    "from plotting_utils import figSize\n",
    "from session_utils import *\n",
    "from recalibration_utils import *\n",
    "from click_utils import *\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "min_nblocks    = 3       # min number of blocks for a session to be include\n",
    "max_ndays      = 30      # accept all pairs of sessions regardless of time between\n",
    "min_R2         = 0.1     # subselect days with good decoder transfer performance \n",
    "\n",
    "\n",
    "f_dir          = glob.glob('D:/T5_ClosedLoop/*')\n",
    "sessions_check = np.load('misc_data/sessions_check.npy', allow_pickle = True).item()\n",
    "files          = get_Sessions(f_dir, min_nblocks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmm import *\n",
    "from hmm_utils import prep_HMMData, get_DiscreteTargetGrid, train_HMMRecalibrate\n",
    "from sklearn.metrics import r2_score\n",
    "import itertools\n",
    "\n",
    "\n",
    "# general settings:\n",
    "np.random.seed(42)\n",
    "diffs           = list()\n",
    "task            = None\n",
    "train_frac      = 0.5\n",
    "sigma           = 2\n",
    "\n",
    "# HMM settings: \n",
    "gridSize         = 20  \n",
    "stayProb         = 0.99\n",
    "inflection_sweep = 70 \n",
    "exp_sweep        = 0.5\n",
    "thresh_sweep     = 0.3\n",
    "\n",
    "\n",
    "#--------------------------\n",
    "\n",
    "nStates       = gridSize**2\n",
    "stateTrans    = np.eye(nStates)*stayProb #Define the state transition matrix, which assumes uniform transition probability of transitioning to new state\n",
    "\n",
    "for x in range(nStates):\n",
    "    idx                = np.setdiff1d(np.arange(nStates), x)\n",
    "    stateTrans[x, idx] = (1-stayProb)/(nStates-1)\n",
    "pStateStart = np.zeros((nStates,1)) + 1/nStates\n",
    "\n",
    "\n",
    "A_file = files[0]\n",
    "B_file = A_file\n",
    "dayA, dayB              = DataStruct(A_file, alignScreens = True), DataStruct(B_file, alignScreens = True)\n",
    "\n",
    "dayA_blocks             = [sessions_check[A_file] if A_file in sessions_check.keys() else None][0]\n",
    "dayB_blocks             = [sessions_check[B_file] if B_file in sessions_check.keys() else None][0] \n",
    "dayA_task, dayB_task, _ = getPairTasks(dayA, dayB, task = task)\n",
    "\n",
    "# obtain features and cursorError targets:\n",
    "Atrain_x, Atest_x, Atrain_y, Atest_y                 = getTrainTest(dayA, train_frac = train_frac, sigma = sigma, blocks = dayA_blocks, task = dayA_task, return_flattened = True)\n",
    "Btrain_x, B_cursorPos, Btrain_y, Btest_x, _, Btest_y = prep_HMMData(dayB, train_frac = train_frac, sigma = sigma, blocks = dayB_blocks, task = task, return_flattened = True)\n",
    "targetPos                                            = Btrain_y + B_cursorPos\n",
    "\n",
    "full_score, full_decoder = traintest_DecoderSupervised([Atrain_x], [Atrain_x], [Atrain_y], [Atrain_y], meanRecal = False)    \n",
    "targLocs                 = get_DiscreteTargetGrid(dayB, gridSize = gridSize, task = dayB_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy, cython\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### %%cython \n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def hmmviterbi_vonmises_parallel(np.ndarray[np.float_t, ndim=2] rawDecodeVec, np.ndarray[np.float_t, ndim=2] stateTransitions, np.ndarray[np.float_t, ndim=2] targLocs, \n",
    "                                 np.ndarray[np.float_t, ndim=2] cursorPos,  np.ndarray[np.float_t, ndim=2] pStateStart, float vmKappa, adjustKappa = None, bint verbose = False):\n",
    "    '''Run viterbi algorithm to find most likely sequence of target states given the cursor position and decoder outputs. Inputs are:\n",
    "\n",
    "        rawDecodeVec (2D array)     - time x 2 array containing decoder outputs at each timepoint\n",
    "        stateTransitions (2D array) - transition probabilities; n_states x n_states\n",
    "        targLocs (2D array)         - n_states x 2 array containing corresponding target locations for each state\n",
    "        cursorPos (2D array)        - time x 2 array of cursor positions\n",
    "        pStateStart (vector)        - starting probabilities for each state \n",
    "        vmKappa (float)             - precision parameter for Von Mises observation model\n",
    "        adjustKappa (method)        - fxn for weighting kappa values; defaults to None\n",
    "        \n",
    "    NOTE:\n",
    "        - we could parallelize a lot of the below code (in the for loop) but it doesn't seem to result in substantial speed gains!\n",
    "            - around ~40 sec run vs 38 sec run during testing\n",
    "            - would need to fully cythonize to see substantial compute time decreases\n",
    "    '''\n",
    "    cdef int numStates           = len(stateTransitions)\n",
    "    cdef int L                   = rawDecodeVec.shape[0]\n",
    "    cdef int[::1] currentState   = np.zeros((L, ), dtype= int)\n",
    "    \n",
    "    cdef int[:, ::1] pTR        = np.zeros((numStates, L), dtype= int)\n",
    "    cdef double[:, ::1] logTR   = np.log(stateTransitions)\n",
    "    cdef np.ndarray v           = np.log(pStateStart)\n",
    "    cdef np.ndarray vOld        = v\n",
    " \n",
    "\n",
    "    # declare variables used later:\n",
    "    cdef np.ndarray[np.float_t, ndim=2] tmpV\n",
    "    cdef np.intp_t count\n",
    "    cdef int[::1] maxIdx\n",
    "    cdef double[::1] maxVal\n",
    "    \n",
    "    # default kappa adjustment - none \n",
    "    if adjustKappa is None:\n",
    "        def adjustKappa(dist):\n",
    "            cdef np.ndarray adjusted = np.ones(dist.shape, dtype = np.float)\n",
    "            return adjusted\n",
    "\n",
    "    # Precompute some values for speedup: \n",
    "    cdef double[::1] observedAngle                       = np.arctan2(rawDecodeVec[:, 1], rawDecodeVec[:, 0])\n",
    "    cdef np.ndarray[np.float_t, ndim=2] tDists           = np.linalg.norm(targLocs - cursorPos[:, np.newaxis, :], axis = 2)\n",
    "    cdef np.ndarray[np.float_t, ndim=3] normPosErr       = (targLocs[:, np.newaxis] - cursorPos) / tDists.T[:, :, np.newaxis]\n",
    "    cdef np.ndarray[np.float_t, ndim=2] expectedAngle    = np.arctan2(normPosErr[:, :, 1], normPosErr[:, :, 0])\n",
    "    cdef np.ndarray[np.float_t, ndim=2] vmKappa_adjusted = vmKappa * adjustKappa(tDists)\n",
    "    cdef np.ndarray[np.float_t, ndim=2] vmProbLog        = (vmKappa_adjusted * np.cos(observedAngle - expectedAngle).T) - np.log(2 * np.pi * np.i0(vmKappa_adjusted))\n",
    "\n",
    "    # loop through the model;  von mises emissions probabilities\n",
    "    for count in range(L):\n",
    "        tmpV          = vOld + logTR\n",
    "        maxIdx        = np.argmax(tmpV, axis = 1).astype('int')\n",
    "        maxVal        = np.take_along_axis(tmpV, np.expand_dims(maxIdx, axis=-1), axis=-1).squeeze(axis=-1)\n",
    "        \n",
    "        pTR[:,count] = maxIdx\n",
    "        v            = vmProbLog[count, :] + maxVal\n",
    "        vOld         = v\n",
    "    \n",
    "    # decide which of the final states is most probable\n",
    "    cdef int finalState = np.argmax(v)\n",
    "    cdef float logP     = v[finalState]\n",
    "\n",
    "    # Now back trace through the model\n",
    "    currentState[L - 1] = finalState\n",
    "\n",
    "    for count in reversed(range(0, L - 1)):\n",
    "        currentState[count] = pTR[int(currentState[count + 1]), count + 1]\n",
    "        if currentState[count] == 0 & verbose == True:\n",
    "            print('stats:hmmviterbi:ZeroTransitionProbability', currentState[ count + 1 ])\n",
    "\n",
    "    return currentState, logP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#from hmm_numba import hmmviterbi_vonmises_parallel\n",
    "\n",
    "def adjust(dist):\n",
    "    coef = 1 / (1 + np.exp(-1 * (dist - 70) * 0.5))\n",
    "    return coef \n",
    "adjust = None\n",
    "\n",
    "x= hmmviterbi_vonmises(rawDecodeVec[:200, :], stateTrans, targLocs, B_cursorPos[:200, :], pStateStart,  4, adjust, False)[0]\n",
    "y= hmmviterbi_vonmises_parallel(rawDecodeVec[:200, :], stateTrans, targLocs, B_cursorPos[:200, :], pStateStart,  4, adjust, False)[0]\n",
    "\n",
    "print(np.linalg.norm(x - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 ms ± 5.48 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "188 ms ± 4.42 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hmmviterbi_vonmises(rawDecodeVec[:200, :], stateTrans, targLocs, B_cursorPos[:200, :], pStateStart, 4, adjust, verbose = False)\n",
    "%timeit hmmviterbi_vonmises_parallel(rawDecodeVec[:200, :], stateTrans, targLocs, B_cursorPos[:200, :], pStateStart, 4, adjust, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 1)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620 ms ± 35.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.07 s ± 42.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "t = np.random.rand(20000, 400)\n",
    "\n",
    "%timeit scipy.special.i0(t)\n",
    "%timeit np.i0(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working -- dont touch\n",
    "\n",
    "%%cython \n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "@cython.boundscheck(True)#\n",
    "@cython.wraparound(False)\n",
    "def hmmviterbi_vonmises_parallel(np.ndarray[np.float_t, ndim=2] rawDecodeVec, np.ndarray[np.float_t, ndim=2] stateTransitions, np.ndarray[np.float_t, ndim=2] targLocs, \n",
    "                                 np.ndarray[np.float_t, ndim=2] cursorPos,  np.ndarray[np.float_t, ndim=2] pStateStart, float vmKappa, adjustKappa = None, bint verbose = False):\n",
    "    '''Run viterbi algorithm to find most likely sequence of target states given the cursor position and decoder outputs. Inputs are:\n",
    "\n",
    "        rawDecodeVec (2D array)     - time x 2 array containing decoder outputs at each timepoint\n",
    "        stateTransitions (2D array) - transition probabilities; n_states x n_states\n",
    "        targLocs (2D array)         - n_states x 2 array containing corresponding target locations for each state\n",
    "        cursorPos (2D array)        - time x 2 array of cursor positions\n",
    "        pStateStart (vector)        - starting probabilities for each state \n",
    "        vmKappa (float)             - precision parameter for Von Mises observation model\n",
    "        adjustKappa (method)        - fxn for weighting kappa values; defaults to None\n",
    "        \n",
    "    NOTE:\n",
    "        - we could parallelize a lot of the below code (in the for loop) but it doesn't seem to result in substantial speed gains!\n",
    "            - around ~40 sec run vs 38 sec run during testing\n",
    "            - would need to fully cythonize to see substantial compute time decreases\n",
    "    '''\n",
    "    cdef int numStates           = len(stateTransitions)\n",
    "    cdef int L                   = rawDecodeVec.shape[0]\n",
    "    cdef int[::1] currentState   = np.zeros((L, ), dtype= int)\n",
    "    \n",
    "    cdef int[:, ::1] pTR        = np.zeros((numStates, L), dtype= int)\n",
    "    cdef double[:, ::1] logTR   = np.log(stateTransitions)\n",
    "    cdef np.ndarray v           = np.log(pStateStart)\n",
    "    cdef np.ndarray vOld        = v\n",
    " \n",
    "\n",
    "    # declare variables used later:\n",
    "    cdef np.ndarray[np.float_t, ndim=2] tmpV\n",
    "    cdef np.intp_t count\n",
    "    cdef int[::1] maxIdx\n",
    "    cdef double[::1] maxVal\n",
    "    \n",
    "    # default kappa adjustment - none \n",
    "    if adjustKappa is None:\n",
    "        def adjustKappa(dist):\n",
    "            cdef np.ndarray adjusted = np.ones(dist.shape, dtype = np.float)\n",
    "            return adjusted\n",
    "\n",
    "    # Precompute some values for speedup: \n",
    "    cdef double[::1] observedAngle                       = np.arctan2(rawDecodeVec[:, 1], rawDecodeVec[:, 0])\n",
    "    cdef np.ndarray[np.float_t, ndim=2] tDists           = np.linalg.norm(targLocs - cursorPos[:, np.newaxis, :], axis = 2)\n",
    "    cdef np.ndarray[np.float_t, ndim=3] normPosErr       = (targLocs[:, np.newaxis] - cursorPos) / tDists.T[:, :, np.newaxis]\n",
    "    cdef np.ndarray[np.float_t, ndim=2] expectedAngle    = np.arctan2(normPosErr[:, :, 1], normPosErr[:, :, 0])\n",
    "    cdef np.ndarray[np.float_t, ndim=2] vmKappa_adjusted = vmKappa * adjustKappa(tDists)\n",
    "    cdef np.ndarray[np.float_t, ndim=2] vmProbLog        = (vmKappa_adjusted * np.cos(observedAngle - expectedAngle).T) - np.log(2 * np.pi * np.i0(vmKappa_adjusted))\n",
    "    #cdef np.ndarray[np.float_t, ndim=2] vmProbLog        = (vmKappa_adjusted * np.cos(observedAngle - expectedAngle).T) - np.log(2 * np.pi * scipy.special.i0(vmKappa_adjusted))\n",
    "\n",
    "    # loop through the model;  von mises emissions probabilities\n",
    "    for count in range(L):\n",
    "        tmpV          = vOld + logTR\n",
    "        maxIdx        = np.argmax(tmpV, axis = 1).astype('int')\n",
    "        maxVal        = np.take_along_axis(tmpV, np.expand_dims(maxIdx, axis=-1), axis=-1).squeeze(axis=-1)\n",
    "        \n",
    "        pTR[:,count] = maxIdx\n",
    "        v            = vmProbLog[count, :] + maxVal\n",
    "        vOld         = v\n",
    "    \n",
    "    # decide which of the final states is most probable\n",
    "    cdef int finalState = np.argmax(v)\n",
    "    cdef float logP     = v[finalState]\n",
    "\n",
    "    # Now back trace through the model\n",
    "    currentState[L - 1] = finalState\n",
    "\n",
    "    for count in reversed(range(0, L - 1)):\n",
    "        currentState[count] = pTR[int(currentState[count + 1]), count + 1]\n",
    "        if currentState[count] == 0 & verbose == True:\n",
    "            print('stats:hmmviterbi:ZeroTransitionProbability', currentState[ count + 1 ])\n",
    "\n",
    "    return currentState, logP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Speech",
   "language": "python",
   "name": "speech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
