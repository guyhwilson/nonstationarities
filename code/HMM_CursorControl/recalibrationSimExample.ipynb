{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# for a reproducible result\n",
    "np.random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define an initial decoder and initial neural tuning properties (mean firing rates and preferred directions).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The first column of initialTuning is the means, and the second two columns are the preferred directions. \n",
    "We make sure that the last two columns are orthogonal (uniformly distributed PDs) \n",
    "and that the tuning strength is set to 1 (norm of the column is 1). '''\n",
    "\n",
    "nUnits                  = 100\n",
    "initialTuning           = np.random.normal(size = (nUnits, 3))\n",
    "initialTuning[:, 1:], R = np.linalg.qr(initialTuning[:, 1:], 'reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The following is a really simple way to build a linear decoder based on the above tuning properties. \n",
    "First we define some velocity vectors (calVelocity), then simulate neural tuning to those vectors (calNeural),\n",
    "and finally use ordinary least squares regression to find a decoder (D) that predicts calVelocity from calNeural. '''\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "nTrainingSteps = 10000\n",
    "calVelocity    = np.random.normal(size = (nTrainingSteps, 2))\n",
    "calNeural      = calVelocity.dot(initialTuning[:,1:].T)  + initialTuning[:, 0].T;  # FR = <velocity, PD> + baseline\n",
    "calNeural      = calNeural + np.random.normal(size = calNeural.shape) * 0.3      # add gaussian noise\n",
    "\n",
    "D              = LinearRegression(fit_intercept = True).fit(calNeural, calVelocity).coef_.T\n",
    "\n",
    "# Normalize the gain of this decoder so that it will output vectors with a magnitude of 1 when the encoded velocity has a magnitude of 1. \n",
    "D[:, 0] = D[:,0] / np.linalg.norm(D[1:, :][:, 0]) / np.linalg.norm(initialTuning[:, 0])\n",
    "D[:, 1] = D[:,1] / np.linalg.norm(D[1:, :][:, 1]) / np.linalg.norm(initialTuning[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Here we define the amount of exponential smoothing used in the decoder (alpha). Values between 0.9 and 0.96 are pretty reasonable. See the paper\n",
    "'A comparison of intention estimation methods for decoder calibration in intracortical brain-computer interfaces' for an explanation of how velocity Kalman \n",
    "filters can be parameterized with a smoothing parameter (alpha), gain parameter (beta, see next section below) and decoding matrix (D). '''\n",
    "\n",
    "alpha       = 0.94\n",
    "delT        = 0.01 # define the time step (10 ms)\n",
    "nDelaySteps = 20   # define the simulated user's visual feedback delay (200 ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a quick sweep of cursor gains to find the optimal one for this task.\n",
    "\n",
    "This is really important so that any new recalibration algorithm doesn't improve performance simply by coincidence,\n",
    "via randomly changing the gain to some better value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The task we are simulating is a fitts style task where targets randomly\n",
    "appear within a box centered at the origin. To acquire the target, the\n",
    "user must hold the cursor on top of the target for half a second. The\n",
    "performance metric of interest is the average total trial time (TTT), or\n",
    "the average amount of time it takes to reach to and fully hold on a target. \n",
    "\n",
    "The 'simulateBCIFitts' does all the work of simulating the BCI user, the\n",
    "neural activity, and the decoder. It returns time series data you can use\n",
    "to see the cursor trajectory and target locations (posTraj & velTraj are\n",
    "the cursor positions and velocities, rawDecTraj is the raw decoded\n",
    "velocity vectors before they are smoothed, conTraj is the user's internal\n",
    "control vector, targTraj is a time series of target locations, neuralTraj\n",
    "is a time series of neural activity, trialStart contains the time step on\n",
    "which each trial started, and ttt has the trial time (in seconds) for each\n",
    "trial. '''\n",
    "\n",
    "possibleGain = np.linspace(0.5,2.5,10)\n",
    "meanTTT      = np.zeros((len(possibleGain),))\n",
    "nSimSteps    = 50000;\n",
    "\n",
    "for g in range(len(possibleGain)):\n",
    "    print(str(g) + ' / ' + str(len(possibleGain)))\n",
    "    \n",
    "    posTraj, velTraj, rawDecTraj, conTraj, targTraj, neuralTraj, trialStart, ttt = simulateBCIFitts(initialTuning, D, alpha, possibleGain(g), nDelaySteps, delT, nSimSteps)\n",
    "    meanTTT[g] = np.mean(ttt)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(possibleGain, meanTTT, '-o')\n",
    "plt.xlabel('Gain')\n",
    "plt.ylabel('Mean Trial Time (s)')\n",
    "\n",
    "minIdx = np.argmin(meanTTT)\n",
    "beta   = possibleGain[minIdx]\n",
    "\n",
    "print('Using gain value beta = ' str(beta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%%\n",
    "%Simulate BCI performance with matched neural tuning and decoder, and an optimized gain\n",
    "nSimSteps = 100000;\n",
    "[posTraj, velTraj, rawDecTraj, conTraj, targTraj, neuralTraj, trialStart, ttt] = ...\n",
    "    simulateBCIFitts(initialTuning, D, alpha, beta, nDelaySteps, delT, nSimSteps);\n",
    "\n",
    "disp(['With a matched, optimized decoder, mean trial time is ' num2str(mean(ttt)) ' s']);\n",
    "\n",
    "%%\n",
    "%Simulate a change in neural tuning (specifically, change the PDs only, making sure the total magnitude of tuning is the same)\n",
    "newTuning = initialTuning;\n",
    "newPD_component = randn(nUnits,2);\n",
    "[Q, R] = qr([initialTuning(:,2:3), newPD_component]);\n",
    "newPD_component = Q(:,3:4);\n",
    "\n",
    "newTuning(:,2:3) = initialTuning(:,2:3)*(0.3) + newPD_component*(sqrt(1-0.3^2));\n",
    "\n",
    "%%\n",
    "%Simulate BCI performance under this change\n",
    "[posTraj_new, velTraj_new, rawDecTraj_new, conTraj_new, targTraj_new, neuralTraj_new, trialStart_new, ttt_new] = ...\n",
    "    simulateBCIFitts(newTuning, D, alpha, beta, nDelaySteps, delT, nSimSteps);\n",
    "\n",
    "disp(['With changed tuning and a mismatched decoder, the mean trial time is ' num2str(mean(ttt_new)) ' s']);\n",
    "\n",
    "%%\n",
    "%This change in PDs effectively decrease the gain of the decoder, since the\n",
    "%tuning strength in the decoder subspace has decreased (factor of 0.3).\n",
    "%Here, we do a control to confirm that performance can't be restored simply\n",
    "%by increasing the gain by (1/0.3) and using the original decoder subspace.\n",
    "[posTraj_control, velTraj_control, rawDecTraj_control, conTraj_control, targTraj_control, neuralTraj_control, trialStart_control, ttt_control] = ...\n",
    "    simulateBCIFitts(newTuning, D, alpha, beta/0.3, nDelaySteps, delT, nSimSteps);\n",
    "\n",
    "disp(['Control: With changed tuning and a mismatched decoder with restored gain, the mean trial time is ' num2str(mean(ttt_new)) ' s']);\n",
    "\n",
    "%%\n",
    "%Here we se a simple HMM to infer the user's intended targets from the raw\n",
    "%(unsmoothed) decoded velocity vectors & cursor positions alone.\n",
    "\n",
    "%Each HMM state corresponds to one target location on a grid. First, get\n",
    "%the grid of target locations.\n",
    "gridSize = 20;\n",
    "[X_loc,Y_loc] = meshgrid(linspace(-0.5, 0.5, gridSize), linspace(-0.5, 0.5, gridSize));\n",
    "targLocs = [X_loc(:), Y_loc(:)];\n",
    "\n",
    "stayProb = 0.9999;\n",
    "nStates = gridSize^2;\n",
    "\n",
    "%Define the state transition matrix, which has a large weight on the\n",
    "%diagonal and small, uniform transition probabilities to other targets.\n",
    "stateTrans = eye(nStates)*stayProb;\n",
    "for x=1:nStates\n",
    "    idx = setdiff(1:nStates, x);\n",
    "    stateTrans(x,idx) = (1-stayProb)/(nStates-1);\n",
    "end\n",
    "\n",
    "pStateStart = zeros(nStates,1) + 1/nStates;\n",
    "\n",
    "%Precision parameter for the von mises distribution.\n",
    "vmKappa = 2;\n",
    "\n",
    "%Infer traget locations from the raw decoder output and cursor positions\n",
    "%using the viterbi algorithm (finds most likely sequence) and the\n",
    "%forwards/backwards algorithm (to find the probabilities). These are custom\n",
    "%functions that I made by modifying the MATLAB hmm routines (hmmviterbi & hmmdecode). \n",
    "[targStates, logP] = hmmviterbi_vonmises(rawDecTraj_new, stateTrans, targLocs, posTraj_new, pStateStart, vmKappa);\n",
    "[pTargState, pSeq] = hmmdecode_vonmises(rawDecTraj_new, stateTrans, targLocs, posTraj_new, pStateStart, vmKappa);\n",
    "\n",
    "%We can find time periods of high certainty, which may be of interest.\n",
    "maxProb = max(pTargState);\n",
    "highProbIdx = find(maxProb>0.8);\n",
    "\n",
    "%See how well the inferred target locations match the true target\n",
    "%locations.\n",
    "inferredTargLoc = targLocs(targStates,:);\n",
    "\n",
    "disp('Correlation between inferred target locations and true locations:');\n",
    "disp(corr(targTraj_new, inferredTargLoc));\n",
    "\n",
    "disp('Correlation between inferred target locations and true locations for periods of high certainty:');\n",
    "disp(corr(targTraj_new(highProbIdx,:), inferredTargLoc(highProbIdx,:)));\n",
    "\n",
    "figure; \n",
    "hold on;\n",
    "plot(targTraj_new); \n",
    "plot(inferredTargLoc,'--');\n",
    "legend({'True Target X','True Target Y','Inferred Target X','Inferred Target Y'});\n",
    "xlabel('Time Step');\n",
    "ylabel('X & Y Target Locations');\n",
    "\n",
    "%%\n",
    "%Now recalibrate the decoder based on the inferred targets.\n",
    "inferredPosErr = inferredTargLoc - posTraj_new;\n",
    "D_new = [ones(length(neuralTraj_new),1), neuralTraj_new] \\ inferredPosErr;\n",
    "decVec_new = [ones(size(neuralTraj_new,1),1), neuralTraj_new] * D_new;\n",
    "\n",
    "%Important: normalize the decoder so that D_new decoders vectors of magnitude 1 when far from the\n",
    "%target. This will restore the original optimal gain.\n",
    "inferredTargDist = sqrt(sum(inferredPosErr.^2,2));\n",
    "inferredTargDir = inferredPosErr ./ inferredTargDist;\n",
    "farIdx = find(inferredTargDist>0.4);\n",
    "projVec = sum(decVec_new(farIdx,:) .* inferredTargDir(farIdx,:),2);\n",
    "\n",
    "D_new = D_new / mean(projVec);\n",
    "\n",
    "%%\n",
    "%Simulate BCI performance with the new decoder\n",
    "[posTraj_recal, velTraj_recal, rawDecTraj_recal, conTraj_recal, targTraj_recal, neuralTraj_recal, trialStart_recal, ttt_recal] = ...\n",
    "    simulateBCIFitts(newTuning, D_new, alpha, beta, nDelaySteps, delT, nSimSteps);\n",
    "\n",
    "disp(['Recalibrating the decoder with inferred HMM targets, the mean trial time is ' num2str(mean(ttt_recal)) ' s']);\n",
    "\n",
    "%%\n",
    "%Now do the same thing, but using the true targets, so we can compare to\n",
    "%the performance of supervised recalibration.\n",
    "truePosErr = targTraj_new - posTraj_new;\n",
    "D_supervised = [ones(length(neuralTraj_new),1), neuralTraj_new] \\ truePosErr;\n",
    "decVec_trueControl = [ones(size(neuralTraj_new,1),1), neuralTraj_new] * D_supervised;\n",
    "\n",
    "trueTargDist = sqrt(sum(truePosErr.^2,2));\n",
    "trueTargDir = truePosErr ./ trueTargDist;\n",
    "farIdx = find(trueTargDist>0.4);\n",
    "projVec = sum(decVec_trueControl(farIdx,:) .* trueTargDir(farIdx,:),2);\n",
    "\n",
    "D_supervised = D_supervised / mean(projVec);\n",
    "\n",
    "[posTraj_recal, velTraj_recal, rawDecTraj_recal, conTraj_recal, targTraj_recal, neuralTraj_recal, trialStart_recal, ttt_recal_super] = ...\n",
    "    simulateBCIFitts(newTuning, D_supervised, alpha, beta, nDelaySteps, delT, nSimSteps);\n",
    "\n",
    "disp(['Recalibrating the decoder with the true targets, the mean trial time is ' num2str(mean(ttt_recal_super)) ' s']);\n",
    "\n",
    "%%\n",
    "%Summarize the performance for all 4 relevant conditions: original\n",
    "%performance, performance when the tuning changes (but the decoder\n",
    "%doesn't), performance with the HMM-powered unsupervised recalibration, and\n",
    "%performance with supervised recalibration. We plot means and 95% CIs.\n",
    "\n",
    "[mu_original,SIGMAHAT,ci_original,SIGMACI] = normfit(ttt);\n",
    "[mu_mismatch,SIGMAHAT,ci_mismatch,SIGMACI] = normfit(ttt_new);\n",
    "[mu_hmmRecal,SIGMAHAT,ci_hmmRecal,SIGMACI] = normfit(ttt_recal);\n",
    "[mu_supervisedRecal,SIGMAHAT,ci_supervisedRecal,SIGMACI] = normfit(ttt_recal_super);\n",
    "\n",
    "mus = {mu_original, mu_mismatch, mu_hmmRecal, mu_supervisedRecal};\n",
    "cis = {ci_original, ci_mismatch, ci_hmmRecal, ci_supervisedRecal};\n",
    "\n",
    "labels = {'Original','Tuning Change','HMM Inference\\newlineRecalibration','Supervised\\newlineRecalibration'};\n",
    "\n",
    "figure\n",
    "hold on;\n",
    "for x=1:length(mus)\n",
    "    plot(x, mus{x}, 'o', 'Color', lines(1),'LineWidth',2);\n",
    "    plot([x,x], cis{x}, '-', 'Color', lines(1),'LineWidth',2);\n",
    "end\n",
    "xlim([0.5, length(mus)+0.5]);\n",
    "ylim([0,max([mus{:}])+0.2]);\n",
    "ylabel('Mean Trial Time (s)');\n",
    "set(gca,'XTick',1:length(mus),'XTickLabel',labels,'XTickLabelRotation',45,'FontSize',12,'LineWidth',2);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.at"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Speech",
   "language": "python",
   "name": "speech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
