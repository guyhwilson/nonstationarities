{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import glob, sys\n",
    "\n",
    "\n",
    "[sys.path.append(f) for f in glob.glob('../utils/*')]\n",
    "from preprocess import DataStruct\n",
    "from plotting_utils import figSize\n",
    "from lineplots import plotsd\n",
    "from hmm_utils import *\n",
    "from hmm import *\n",
    "from session_utils import *\n",
    "from recalibration_utils import *\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import FactorAnalysis, PCA\n",
    "\n",
    "min_nblocks = 3       # min number of blocks for a session to be include\n",
    "max_ndays   = 30      # accept all pairs of sessions regardless of time between\n",
    "min_r       = 0.33    # subselect days where mean recalibration alone works okayish\n",
    "sigma       = 2       # causal gaussian smoothing for TXs\n",
    "task        = None    # subselect any tasks\n",
    "train_size  = 0.67    # fraction of blocks for training data\n",
    "gridSize    = 20      \n",
    "\n",
    "data_dir    = '/oak/stanford/groups/shenoy/gwilson/nonstationarities/'\n",
    "participant = 'T5/new/'\n",
    "save_path   = '/oak/stanford/groups/shenoy/gwilson/nonstationarities/T5/test/'\n",
    "\n",
    "\n",
    "# load data:\n",
    "files       = loadDataset(data_dir, participant)\n",
    "\n",
    "# preprocess by selecting sessions with a minimal block count:\n",
    "sessions_check = np.load('../utils/misc_data/NewSessions_check.npy', allow_pickle = True).item()\n",
    "files          = get_Sessions(files, min_nblocks, manually_remove = None)\n",
    "\n",
    "pairs    = get_SessionPairs(files, max_ndays = max_ndays)\n",
    "n_pairs  = len(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate dictionaries containing data for session-pairs, and save to dataset folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getScreenBounds(struct):\n",
    "    targpos_data  = struct.targetPos_continuous\n",
    "    X_min, X_max  = targpos_data[:, 0].min() - 20, targpos_data[:, 0].max() + 20\n",
    "    Y_min, Y_max  = targpos_data[:, 1].min() - 20, targpos_data[:, 1].max() + 20\n",
    "    \n",
    "    return X_min, X_max, Y_min, Y_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/software/user/open/py-scikit-learn/0.19.1_py36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.3 % complete\n",
      "18.5 % complete\n",
      "27.8 % complete\n",
      "37.0 % complete\n",
      "46.3 % complete\n",
      "55.6 % complete\n",
      "64.8 % complete\n",
      "74.1 % complete\n",
      "83.3 % complete\n",
      "92.6 % complete\n"
     ]
    }
   ],
   "source": [
    "from hmm import *\n",
    "from hmm_utils import prep_HMMData, get_DiscreteTargetGrid, train_HMMRecalibrate\n",
    "import scipy, sklearn\n",
    "import itertools\n",
    "\n",
    "pearsons = list()\n",
    "R2s      = list()\n",
    "\n",
    "for i, (A_file, B_file) in enumerate(pairs):\n",
    "    dayA = DataStruct(A_file, alignScreens = True, causal_filter = sigma)\n",
    "    dayB = DataStruct(B_file, alignScreens = True, causal_filter = sigma)\n",
    "    \n",
    "\n",
    "    #dayA_blocks             = [sessions_check[A_file] if A_file in sessions_check.keys() else None][0]\n",
    "    #dayB_blocks             = [sessions_check[B_file] if B_file in sessions_check.keys() else None][0] \n",
    "    #dayA_task, dayB_task, _ = getPairTasks(dayA, dayB, task = task)\n",
    "    dayA_blocks, dayB_blocks = None, None\n",
    "    dayA_task, dayB_task    = None, None\n",
    "\n",
    "    # obtain features and cursorError targets:\n",
    "    Atrain_x, Atest_x, Atrain_y, Atest_y  = getTrainTest(dayA, train_size = train_size, blocks = dayA_blocks, task = dayA_task, returnFlattened = True)    \n",
    "    Atrain_x, Atest_x  = get_BlockwiseMeanSubtracted(Atrain_x, Atest_x, concatenate = True)\n",
    "    Atrain_y           = np.concatenate(Atrain_y)\n",
    "    Atest_y            = np.concatenate(Atest_y)\n",
    "\n",
    "    Btrain_x, Btest_x, Btrain_y, Btest_y, B_cursorPos, _  = getTrainTest(dayB, train_size = train_size, blocks = dayB_blocks, task = dayB_task, \n",
    "                                                                         returnFlattened = True, returnCursor = True)    \n",
    "\n",
    "    Btrain_x, Btest_x  = get_BlockwiseMeanSubtracted(Btrain_x, Btest_x, concatenate = True)\n",
    "    Btrain_y           = np.concatenate(Btrain_y)\n",
    "    Btest_y            = np.concatenate(Btest_y)\n",
    "    B_cursorPos        = np.concatenate(B_cursorPos)\n",
    "\n",
    "    A_decoder = LinearRegression(fit_intercept = False, normalize = False).fit(Atrain_x, Atrain_y)\n",
    "    Bpred_y   = A_decoder.predict(Btest_x)\n",
    "    \n",
    "    R2score  = sklearn.metrics.r2_score(Btest_y, Bpred_y)\n",
    "    pearsonr = scipy.stats.pearsonr(Btest_y.flatten(), Bpred_y.flatten())[0]\n",
    "    \n",
    "    pearsons.append(pearsonr)\n",
    "    R2s.append(R2score)\n",
    "    \n",
    "    if pearsonr >= min_r:\n",
    "        # add smoothing and session-specific information\n",
    "        pair_data = dict()\n",
    "        pair_data['A_file']     = A_file\n",
    "        pair_data['B_file']     = B_file\n",
    "        pair_data['days_apart'] = daysBetween(dayA.date, dayB.date)\n",
    "        pair_data['task']       = task\n",
    "        pair_data['train_size'] = train_size\n",
    "        pair_data['smoothing']  = sigma\n",
    "\n",
    "        pair_data['A_decoder']           = A_decoder\n",
    "        pair_data['mean_recal_R2']       = R2score\n",
    "        pair_data['mean_recal_pearsonr'] = pearsonr\n",
    "\n",
    "        pair_data['A_train_neural']  = Atrain_x\n",
    "        pair_data['A_test_neural']   = Atest_x\n",
    "        pair_data['A_train_targvec'] = Atrain_y\n",
    "        pair_data['A_test_targvec']  = Atest_y\n",
    "\n",
    "        pair_data['B_train_neural']  = Btrain_x\n",
    "        pair_data['B_test_neural']   = Btest_x\n",
    "        pair_data['B_train_targvec'] = Btrain_y\n",
    "        pair_data['B_test_targvec']  = Btest_y\n",
    "        pair_data['B_train_cursor']  = B_cursorPos        \n",
    "        pair_data['B_screenBounds']  = getScreenBounds(dayB)\n",
    "\n",
    "        save_fname = dayA.date + '_to_' + dayB.date + '.npy'\n",
    "        np.save(save_path + save_fname, pair_data)\n",
    "\n",
    "    if (i + 1) % int(np.round(len(pairs) / 10)) == 0:\n",
    "        print(np.round((i + 1) * 100 / len(pairs), 1), '% complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'figSize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0b2a23209bdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfigSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#lims = [-1, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR2s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpearsons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxhline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'figSize' is not defined"
     ]
    }
   ],
   "source": [
    "figSize(5, 5)\n",
    "\n",
    "#lims = [-1, 1]\n",
    "plt.scatter(R2s, pearsons, alpha = 0.4)\n",
    "plt.axhline(0.33, color = 'k', linestyle = '--', alpha = 0.2)\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.show()\n",
    "plt.xlabel('$R^2$')\n",
    "plt.ylabel('Pearson r')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
