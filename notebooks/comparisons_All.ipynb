{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systematic performance comparisons\n",
    "\n",
    "Compare the following for recalibrating T5 cursor decoders:\n",
    "- mean recalibration\n",
    "- subspace realignment (optimized settings from `optimize_SubspaceRealignment.ipynb`)\n",
    "- HMM (optimized settings from `optimize_vanillaHMM.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4a901650a0c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'HMM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mopt_dict\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mscores_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msweep_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_subsetDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Stabilizer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "[sys.path.append(f) for f in glob.glob('../utils/*')]\n",
    "import preprocess, sweep_utils\n",
    "from plotting_utils import figSize\n",
    "from lineplots import plotsd\n",
    "from session_utils import *\n",
    "from recalibration_utils import *\n",
    "from click_utils import *\n",
    "\n",
    "import sweep_utils\n",
    "\n",
    "\n",
    "DATA_DIR = '/oak/stanford/groups/shenoy/gwilson/nonstationarities/T5/'\n",
    "methods  = ['HMM', 'Stabilizer', 'HMM-Stabilizer']\n",
    "params   = [['kappa', 'inflection', 'exp'], ['method', 'n_components', 'B', 'thresh'], []]\n",
    "scores   = list()\n",
    "\n",
    "for m, p in zip(methods, params):\n",
    "    files     = glob.glob(DATA_DIR + m + '/*/*')\n",
    "    scores_df = sweep_utils.getSummaryDataFrame(files, p + ['R2_score', 'pearson_r', 'days_apart', 'file'])\n",
    "    \n",
    "    if m == 'HMM':\n",
    "        opt_dict  = dict(zip(p, [2, 50, 0.1]))\n",
    "        scores_df = sweep_utils.get_subsetDF(scores_df, opt_dict)\n",
    "    if m == 'Stabilizer':\n",
    "        opt_dict  = dict(zip(p, ['FactorAnalysis', 8, 180, 0.01]))\n",
    "        scores_df = sweep_utils.get_subsetDF(scores_df, opt_dict)\n",
    "    scores.append(scores_df)\n",
    "    \n",
    "    print(m, ' results loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c031d3dd82fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at performance as a function of time between reference and new session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "n_bootstraps = 500\n",
    "\n",
    "bs_models  = list()\n",
    "opt_scores = list()\n",
    "for i in range(5):\n",
    "    # build a bootstrapping model:\n",
    "    bootstrap_lr = BaggingRegressor(LinearRegression(), n_estimators = n_bootstraps, bootstrap = True, random_state = 42)\n",
    "    bootstrap_lr.fit(diffs[:, np.newaxis], scores[i, :])\n",
    "    bs_models.append(bootstrap_lr.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figSize(7, 15)\n",
    "\n",
    "colors = ['k', 'b', 'orange', 'r', 'orange']\n",
    "labels = ['None', 'Means', 'Full', 'Subspace', 'HMM']\n",
    "for i, bs in enumerate(bs_models):\n",
    "    if i in [0, 1, 4]:\n",
    "        for estimator in bs:\n",
    "            plt.plot(diffs, estimator.predict(diffs[:, np.newaxis]), alpha = 0.01, color = colors[i])\n",
    "        plt.scatter(diffs, scores[i, :], label = labels[i], color = colors[i])\n",
    "plt.xlabel('Days between sessions')\n",
    "plt.ylabel('R^2 (holdout)')\n",
    "plt.title('Recalibration R^2 as a function of time between sessions', fontweight = 'bold')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[4, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check out badly performing days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figSize(15, 15)\n",
    "\n",
    "bad_days      = np.where(np.logical_and(diffs < 40, scores[4, :] < 0.1))[0]\n",
    "good_days     = np.where(np.logical_and(diffs < 40, scores[4, :] > 0.3))[0]\n",
    "width, height = np.ceil(np.sqrt(len(bad_days))).astype('int'), np.ceil(np.sqrt(len(bad_days))).astype('int')\n",
    "FR_diffs      = np.zeros((2,  192, len(files) - 1, ))\n",
    "decoder_preds = list()\n",
    "\n",
    "for i in range(len(files) - 1):\n",
    "    dayA = DataStruct(files[i])\n",
    "    dayB = DataStruct(files[i + 1])\n",
    "\n",
    "    if sum(dayB.trialType == task) * sum(dayA.trialType == task) != 0:\n",
    "        dayA_task, dayB_task = 'cursor', 'cursor'   # try to get same task type for both sesions\n",
    "    else:\n",
    "        dayA_task = np.unique(dayA.trialType)[0]\n",
    "        dayB_task = np.unique(dayB.trialType)[0]\n",
    "\n",
    "    # Fit day A decoders: \n",
    "    Atrain_x, Atest_x, Atrain_y, Atest_y = getTrainTest(dayA, train_frac = train_frac, task = dayA_task, return_flattened = True)\n",
    "    Btrain_x, Btest_x, Btrain_y, Btest_y = getTrainTest(dayB, train_frac = train_frac, task = dayB_task, return_flattened = True)\n",
    "    \n",
    "    FR_diffs[0, :, i] = Atrain_x.mean(axis = 0)\n",
    "    FR_diffs[1, :, i] = Btrain_x.mean(axis = 0)\n",
    "    lm_a              = LinearRegression(fit_intercept = False).fit(Atrain_x - Atrain_x.mean(axis = 0), Atrain_y)\n",
    "    preds             = lm_a.predict(Btest_x - Btest_x.mean(axis = 0))\n",
    "    \n",
    "    decoder_preds.append([Btest_y, preds])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "subplt_size = 5\n",
    "plt_days    = bad_days\n",
    "\n",
    "#----------------------------------\n",
    "figSize(subplt_size * len(plt_days), subplt_size * 3)\n",
    "\n",
    "coord_type = ['X', 'Y']\n",
    "for j, i in enumerate(plt_days):\n",
    "    plt.subplot(len(plt_days), 3, 1 + (j * 3))\n",
    "    x    = FR_diffs[0, :, i]\n",
    "    y    = FR_diffs[1, :, i]\n",
    "    corr = spearmanr(x, y)[0] \n",
    "    \n",
    "    plt.scatter(x, y, color = 'b')\n",
    "    maxval = max(x.max(), y.max())\n",
    "    plt.xlim([0, maxval + 10])\n",
    "    plt.ylim([0, maxval + 10])\n",
    "    plt.xlabel('Mean FRs (reference)')\n",
    "    plt.ylabel('Mean FRs (new)')\n",
    "    plt.plot(plt.xlim(), plt.xlim(), linestyle = '--', color = 'k')\n",
    "    plt.title('Mean FRs: r = ' + str(np.round(corr, 3)))\n",
    "    \n",
    "    for coord in range(2):\n",
    "        x    = decoder_preds[i][0][:, coord]\n",
    "        y    = decoder_preds[i][1][:, coord]\n",
    "        corr = r2_score(x, y)\n",
    "        #corr = np.corrcoef(x, y)[0, 1]\n",
    "\n",
    "        plt.subplot(len(bad_days), 3, coord + 2 + (j * 3))\n",
    "        plt.plot(x[4000:5000], color = 'k')\n",
    "        plt.plot(y[4000:5000], color = 'r')\n",
    "                             \n",
    "        maxval = max(x.max(), y.max())\n",
    "        minval = min(x.min(), y.min())\n",
    "        #plt.xlim([minval, maxval ])\n",
    "        #plt.ylim([minval, maxval ])\n",
    "        plt.xlabel('Time (example period)')\n",
    "        plt.ylabel('Coefficients (new)')\n",
    "        plt.title(coord_type[coord] + ' predictions: R^2 = ' + str(np.round(corr, 3)))\n",
    "\n",
    "plt.suptitle('Changes between reference and new day', fontweight = 'bold')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from resample import bootstrap_LinearRegression\n",
    "figSize(10, 20)\n",
    "\n",
    "\n",
    "plt_days = np.where(diffs < 4)[0]\n",
    "\n",
    "#-----------------------------------\n",
    "FR_changes = np.abs(np.mean(FR_diffs[1, :, :] - FR_diffs[0, :, :], axis = 0))\n",
    "FR_corr    = [spearmanr(FR_diffs[1, :, i], FR_diffs[0, :, i])[0] for i in range(len(files) - 1) ]\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(FR_changes, dayB_HMMscores[opt_D, opt_B, :])\n",
    "#plt.scatter(FR_changes, dayB_HMMscores[opt_D, opt_B, :] / dayB_scores[opt_D, opt_B, :])\n",
    "\n",
    "for i in plt_days:\n",
    "    plt.scatter(FR_changes[i], dayB_HMMscores[opt_D, opt_B, i], color = 'r')\n",
    "plt.ylim([-1, 1])\n",
    "plt.xlabel('Mean FR difference')\n",
    "plt.ylabel('Recalibration performance (R^2)')\n",
    "plt.title('HMM performance vs. mean FR difference', fontweight = 'bold')\n",
    "\n",
    "# bootstrap linear regression:\n",
    "lm, means, coefs = bootstrap_LinearRegression(FR_changes[:, np.newaxis], dayB_HMMscores[opt_D, opt_B, :], regressor = TheilSenRegressor(), n_bootstraps= 500, random_state= 42)\n",
    "\n",
    "for i in range(500):\n",
    "    plt.plot(FR_changes, means[i, :] + np.multiply(FR_changes, coefs[i, :]), alpha = 0.01, color = 'b')\n",
    "plt.plot(FR_changes, lm.predict(FR_changes[:, np.newaxis]), alpha = 1, color = 'b')\n",
    "    \n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "decoder_R2 = np.asarray([r2_score(decoder_preds[i][0], decoder_preds[i][1]) for i in range(len(files) - 1)])\n",
    "\n",
    "plt.scatter(decoder_R2, dayB_HMMscores[opt_D, opt_B, :])\n",
    "for i in plt_days:\n",
    "    plt.scatter(decoder_R2[i], dayB_HMMscores[opt_D, opt_B, i], color = 'r')\n",
    "plt.ylim([-1, 1])\n",
    "plt.xlim([-1, 1])\n",
    "plt.xlabel('Reference decoder performance on new day (R^2)')\n",
    "plt.ylabel('Recalibration performance (R^2)')\n",
    "plt.title('HMM performance vs. non-recalibrated decoder performance', fontweight = 'bold')\n",
    "\n",
    "lm, means, coefs = bootstrap_LinearRegression(decoder_R2[:, np.newaxis], dayB_HMMscores[opt_D, opt_B, :], regressor = TheilSenRegressor(), n_bootstraps= 500, random_state= 42)\n",
    "\n",
    "#for i in range(500):\n",
    "#    plt.plot(dplt.xlim(), means[i, :] + np.multiply(np.asarray(plt.xlim()), coefs[i, :]), alpha = 0.01, color = 'b')\n",
    "plt.plot(plt.xlim(), lm.predict(np.asarray(plt.xlim())[:, np.newaxis]), alpha = 1, color = 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bad_days:\n",
    "    print(DataStruct(files[i]).date, '  ', DataStruct(files[i+1]).date )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
