{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "import glob, sys\n",
    "import pickle\n",
    "\n",
    "[sys.path.append(f) for f in glob.glob('../utils/*')]\n",
    "from preprocess import *\n",
    "from plotting_utils import *\n",
    "from lineplots import plotsd\n",
    "from stabilizer_utils import *\n",
    "from recalibration_utils import *\n",
    "from session_utils import *\n",
    "\n",
    "from CosineTuning import *\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "min_nblocks    = 2\n",
    "participant    = 'T5'\n",
    "\n",
    "\n",
    "FILE_DIR       = '/oak/stanford/groups/henderj/ghwilson/nonstationarities/' + participant + '/'\n",
    "fig_path       = '/home/users/ghwilson/projects/nonstationarities/figures/'\n",
    "filelist       = glob.glob(FILE_DIR + 'historical/*')\n",
    "filelist.extend(glob.glob(FILE_DIR + 'new/*'))\n",
    "\n",
    "block_constraints = getBlockConstraints(FILE_DIR)\n",
    "\n",
    "files          = get_Sessions(filelist, min_nblocks,  block_constraints = block_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "\n",
    "def rotateVelocity(intention_vectors, decoder_velocity):\n",
    "    '''Rotate velocity signals toward target, as in KF ReFIT. Can \n",
    "    view as rescaling the intention signal estimates based on ground-truth\n",
    "    speed as well. Inputs are:\n",
    "    \n",
    "        intention_vectors (2D float) - time x 2 of point-to-target signals\n",
    "        decoded_velocity (2D float)  - time x 2 of ground-truth cursor velocities\n",
    "        '''\n",
    "    \n",
    "    # standardize intention estimates\n",
    "    intention_vectors /= np.linalg.norm(intention_vectors, axis=1,keepdims=True) \n",
    "    \n",
    "    # now rescale according to decoded speeds\n",
    "    intention_vectors *= np.linalg.norm(decoder_velocity, axis=1, keepdims=True)\n",
    "    \n",
    "    return intention_vectors\n",
    "\n",
    "\n",
    "def processSingleSession(file, cfg):\n",
    "    \n",
    "    n_restarts   = 10\n",
    "    session_dict = dict()\n",
    "    fields       = ['TX', 'cursorPos', 'targetPos', 'decVel']\n",
    "    \n",
    "    # First calculate encoding and decoding weights independently for each session:\n",
    "    session = DataStruct(file, causal_filter = cfg['sigma'], alignScreens = True)\n",
    "    blocks  = block_constraints[file]\n",
    "\n",
    "    # obtain features and cursorError targets:\n",
    "    session_dat = getTrainTest(session, fields = fields, train_size = cfg['train_size'], \n",
    "                               task = cfg['task'], blocks = blocks, returnFlattened = True) \n",
    "    session_dict['decoder_means'] = session_dat['test_TX'][-1].mean(axis = 0)\n",
    "    \n",
    "    train_vel = np.concatenate(session_dat['train_decVel'])\n",
    "    train_y   = np.concatenate(session_dat['train_targetPos']) - np.concatenate(session_dat['train_cursorPos'])\n",
    "    test_y    = np.concatenate(session_dat['test_targetPos']) - np.concatenate(session_dat['test_cursorPos'])\n",
    "    train_x, test_x = subtractMeans(session_dat['train_TX'], session_dat['test_TX'], method = 'blockwise', concatenate = True)\n",
    "\n",
    "    scores = np.zeros((2,))\n",
    "    \n",
    "    rotated_y = rotateVelocity(train_y, train_vel)\n",
    "    \n",
    "    scores[i]   = LinearRegression().fit(train_x, train_y).score(test_x, test_y)\n",
    "    scores[i+1] = LinearRegression().fit(train_x, rotated_y).score(test_x, test_y)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2577/1833499781.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_decVel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "len(session_dat['train_decVel'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2577/1054599154.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  intention_vectors /= np.linalg.norm(intention_vectors, axis=1,keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4737629572341507\n",
      "0.42326213627049886\n"
     ]
    }
   ],
   "source": [
    "i = 49\n",
    "\n",
    "n_restarts   = 10\n",
    "session_dict = dict()\n",
    "fields       = ['TX', 'cursorPos', 'targetPos', 'decVel']\n",
    "\n",
    "# First calculate encoding and decoding weights independently for each session:\n",
    "session = DataStruct(files[i], causal_filter = 2, alignScreens = True)\n",
    "blocks  = block_constraints[files[i]]\n",
    "\n",
    "# obtain features and cursorError targets:\n",
    "session_dat = getTrainTest(session, fields = fields, train_size = cfg['train_size'], \n",
    "                           task = cfg['task'], blocks = blocks, returnFlattened = True) \n",
    "session_dict['decoder_means'] = session_dat['test_TX'][-1].mean(axis = 0)\n",
    "\n",
    "train_vel = np.concatenate(session_dat['train_decVel'])\n",
    "train_y   = np.concatenate(session_dat['train_targetPos']) - np.concatenate(session_dat['train_cursorPos'])\n",
    "test_y    = np.concatenate(session_dat['test_targetPos']) - np.concatenate(session_dat['test_cursorPos'])\n",
    "train_x, test_x = subtractMeans(session_dat['train_TX'], session_dat['test_TX'], method = 'blockwise', concatenate = True)\n",
    "\n",
    "scores = np.zeros((2,))\n",
    "\n",
    "\n",
    "rotated_y = rotateVelocity(np.copy(train_y), train_vel)\n",
    "bad_idxs  = np.where(np.isnan(rotated_y))[0]\n",
    "train_x   = np.delete(train_x, bad_idxs, axis=0)\n",
    "rotated_y = np.delete(rotated_y, bad_idxs, axis=0)\n",
    "train_y   = np.delete(train_y, bad_idxs, axis=0)\n",
    "\n",
    "\n",
    "preds     = LinearRegression().fit(train_x, train_y).predict(test_x)\n",
    "rot_preds = LinearRegression().fit(train_x, rotated_y).predict(test_x)\n",
    "\n",
    "print(np.corrcoef(preds.flatten(), test_y.flatten())[0,1])\n",
    "print(np.corrcoef(rot_preds.flatten(), test_y.flatten())[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   1 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=10)]: Done   2 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done   3 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done   4 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done   5 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done   6 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done   7 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done   8 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done   9 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done  10 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done  11 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done  13 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done  14 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done  15 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done  16 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done  17 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done  18 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done  19 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done  20 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=10)]: Done  22 tasks      | elapsed:    7.9s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (22249,2) (488,1) (22249,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/users/ghwilson/.local/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"/home/users/ghwilson/.local/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/users/ghwilson/.local/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/users/ghwilson/.local/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/users/ghwilson/.local/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/tmp/ipykernel_2577/1054599154.py\", line 47, in processSingleSession\n  File \"/tmp/ipykernel_2577/1054599154.py\", line 20, in rotateVelocity\nValueError: operands could not be broadcast together with shapes (22249,2) (488,1) (22249,2) \n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2577/639765179.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#    print(file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdict_list\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessSingleSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0msession_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/oak/stanford/groups/henderj/ghwilson/miniconda3/envs/nonstationarities/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/oak/stanford/groups/henderj/ghwilson/miniconda3/envs/nonstationarities/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (22249,2) (488,1) (22249,2) "
     ]
    }
   ],
   "source": [
    "# general settings:\n",
    "np.random.seed(42)\n",
    "cfg = dict()\n",
    "\n",
    "cfg['task']         = None\n",
    "cfg['train_size']   = 0.5\n",
    "cfg['sigma']        = 2\n",
    "\n",
    "# --------------------------------------------------\n",
    "#dict_list = list()\n",
    "#for file in files:\n",
    "#    dict_list = processSingleSession(file, cfg) \n",
    "#    print(file)\n",
    "\n",
    "dict_list    = Parallel(n_jobs=10, verbose = 11)(delayed(processSingleSession)(file, cfg) for file in files)\n",
    "session_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nonstationarities (3.9)",
   "language": "python",
   "name": "nonstationarities"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
