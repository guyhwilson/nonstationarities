{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "[sys.path.append(f) for f in glob.glob('utils/*')]\n",
    "from preprocess import DataStruct\n",
    "from firingrate import raster2FR\n",
    "from plotting_utils import figSize\n",
    "from session_utils import *\n",
    "from recalibration_utils import *\n",
    "from click_utils import *\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "min_nblocks    = 3       # min number of blocks for a session to be include\n",
    "max_ndays      = 30      # accept all pairs of sessions regardless of time between\n",
    "min_R2         = 0.1     # subselect days with good decoder transfer performance \n",
    "\n",
    "\n",
    "f_dir          = glob.glob('D:/T5_ClosedLoop/historical/*')\n",
    "sessions_check = np.load('misc_data/OldSessions_check.npy', allow_pickle = True).item()\n",
    "files          = get_Sessions(f_dir, min_nblocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmm import *\n",
    "from hmm_utils import prep_HMMData, get_DiscreteTargetGrid, train_HMMRecalibrate\n",
    "from sklearn.metrics import r2_score\n",
    "import itertools\n",
    "\n",
    "\n",
    "# general settings:\n",
    "np.random.seed(42)\n",
    "diffs           = list()\n",
    "task            = None\n",
    "train_size      = 0.5\n",
    "sigma           = 2\n",
    "\n",
    "# HMM settings: \n",
    "gridSize         = 20  \n",
    "stayProb         = 0.99\n",
    "inflection_sweep = 70 \n",
    "exp_sweep        = 0.5\n",
    "thresh_sweep     = 0.3\n",
    "\n",
    "\n",
    "#--------------------------\n",
    "\n",
    "nStates       = gridSize**2\n",
    "stateTrans    = np.eye(nStates)*stayProb #Define the state transition matrix, which assumes uniform transition probability of transitioning to new state\n",
    "\n",
    "for x in range(nStates):\n",
    "    idx                = np.setdiff1d(np.arange(nStates), x)\n",
    "    stateTrans[x, idx] = (1-stayProb)/(nStates-1)\n",
    "pStateStart = np.zeros((nStates,1)) + 1/nStates\n",
    "\n",
    "\n",
    "A_file = files[0]\n",
    "B_file = A_file\n",
    "dayA, dayB              = DataStruct(A_file, alignScreens = True), DataStruct(B_file, alignScreens = True)\n",
    "\n",
    "dayA_blocks             = [sessions_check[A_file] if A_file in sessions_check.keys() else None][0]\n",
    "dayB_blocks             = [sessions_check[B_file] if B_file in sessions_check.keys() else None][0] \n",
    "dayA_task, dayB_task, _ = getPairTasks(dayA, dayB, task = task)\n",
    "\n",
    "# obtain features and cursorError targets:\n",
    "Atrain_x, Atest_x, Atrain_y, Atest_y  = getTrainTest(dayA, train_size = train_size, sigma = sigma, blocks = dayA_blocks, task = dayA_task, returnFlattened = True)    \n",
    "Atrain_x, Atest_x  = get_BlockwiseMeanSubtracted(Atrain_x, Atest_x, concatenate = True)\n",
    "Atrain_y           = np.concatenate(Atrain_y)\n",
    "Atest_y            = np.concatenate(Atest_y)\n",
    "\n",
    "Btrain_x, Btest_x, Btrain_y, Btest_y, B_cursorPos, _  = getTrainTest(dayB, train_size = train_size, sigma = sigma, blocks = dayB_blocks, task = dayB_task, \n",
    "                                                                         returnFlattened = True, returnCursor = True)    \n",
    "Btrain_x, Btest_x  = get_BlockwiseMeanSubtracted(Btrain_x, Btest_x, concatenate = True)\n",
    "Btrain_y           = np.concatenate(Btrain_y)\n",
    "Btest_y            = np.concatenate(Btest_y)\n",
    "B_cursorPos        = np.concatenate(B_cursorPos)\n",
    "targetPos          = Btrain_y + B_cursorPos\n",
    "\n",
    "full_score, full_decoder = traintest_DecoderSupervised([Atrain_x], [Atrain_x], [Atrain_y], [Atrain_y], meanRecal = False)    \n",
    "targLocs                 = get_DiscreteTargetGrid(dayB, gridSize = gridSize, task = dayB_task)\n",
    "\n",
    "rawDecodeVec = full_decoder.predict(Btrain_x - Btrain_x.mean(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizing HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imporCosineTuningcipy, cython\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### %%cython \n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def hmmviterbi_vonmises_parallel(np.ndarray[np.float_t, ndim=2] rawDecodeVec, np.ndarray[np.float_t, ndim=2] stateTransitions, np.ndarray[np.float_t, ndim=2] targLocs, \n",
    "                                 np.ndarray[np.float_t, ndim=2] cursorPos,  np.ndarray[np.float_t, ndim=2] pStateStart, float vmKappa, adjustKappa = None, bint verbose = False):\n",
    "    '''Run viterbi algorithm to find most likely sequence of target states given the cursor position and decoder outputs. Inputs are:\n",
    "\n",
    "        rawDecodeVec (2D array)     - time x 2 array containing decoder outputs at each timepoint\n",
    "        stateTransitions (2D array) - transition probabilities; n_states x n_states\n",
    "        targLocs (2D array)         - n_states x 2 array containing corresponding target locations for each state\n",
    "        cursorPos (2D array)        - time x 2 array of cursor positions\n",
    "        pStateStart (vector)        - starting probabilities for each state \n",
    "        vmKappa (float)             - precision parameter for Von Mises observation model\n",
    "        adjustKappa (method)        - fxn for weighting kappa values; defaults to None\n",
    "        \n",
    "    NOTE:\n",
    "        - we could parallelize a lot of the below code (in the for loop) but it doesn't seem to result in substantial speed gains!\n",
    "            - around ~40 sec run vs 38 sec run during testing\n",
    "            - would need to fully cythonize to see substantial compute time decreases\n",
    "    '''\n",
    "    cdef int numStates           = len(stateTransitions)\n",
    "    cdef int L                   = rawDecodeVec.shape[0]\n",
    "    cdef int[::1] currentState   = np.zeros((L, ), dtype= int)\n",
    "    \n",
    "    cdef int[:, ::1] pTR        = np.zeros((numStates, L), dtype= int)\n",
    "    cdef double[:, ::1] logTR   = np.log(stateTransitions)\n",
    "    cdef np.ndarray v           = np.log(pStateStart)\n",
    "    cdef np.ndarray vOld        = v\n",
    " \n",
    "\n",
    "    # declare variables used later:\n",
    "    cdef np.ndarray[np.float_t, ndim=2] tmpV\n",
    "    cdef np.intp_t count\n",
    "    cdef int[::1] maxIdx\n",
    "    cdef double[::1] maxVal\n",
    "    \n",
    "    # default kappa adjustment - none \n",
    "    if adjustKappa is None:\n",
    "        def adjustKappa(dist):\n",
    "            cdef np.ndarray adjusted = np.ones(dist.shape, dtype = np.float)\n",
    "            return adjusted\n",
    "\n",
    "    # Precompute some values for speedup: \n",
    "    cdef double[::1] observedAngle                       = np.arctan2(rawDecodeVec[:, 1], rawDecodeVec[:, 0])\n",
    "    cdef np.ndarray[np.float_t, ndim=2] tDists           = np.linalg.norm(targLocs - cursorPos[:, np.newaxis, :], axis = 2)\n",
    "    cdef np.ndarray[np.float_t, ndim=3] normPosErr       = (targLocs[:, np.newaxis] - cursorPos) / tDists.T[:, :, np.newaxis]\n",
    "    cdef np.ndarray[np.float_t, ndim=2] expectedAngle    = np.arctan2(normPosErr[:, :, 1], normPosErr[:, :, 0])\n",
    "    cdef np.ndarray[np.float_t, ndim=2] vmKappa_adjusted = vmKappa * adjustKappa(tDists)\n",
    "    cdef np.ndarray[np.float_t, ndim=2] vmProbLog        = (vmKappa_adjusted * np.cos(observedAngle - expectedAngle).T) - np.log(2 * np.pi * np.i0(vmKappa_adjusted))\n",
    "\n",
    "    # loop through the model;  von mises emissions probabilities\n",
    "    for count in range(L):\n",
    "        tmpV          = vOld + logTR\n",
    "        maxIdx        = np.argmax(tmpV, axis = 1).astype('int')\n",
    "        maxVal        = np.take_along_axis(tmpV, np.expand_dims(maxIdx, axis=-1), axis=-1).squeeze(axis=-1)\n",
    "        \n",
    "        pTR[:,count] = maxIdx\n",
    "        v            = vmProbLog[count, :] + maxVal\n",
    "        vOld         = v\n",
    "    \n",
    "    # decide which of the final states is most probable\n",
    "    cdef int finalState = np.argmax(v)\n",
    "    cdef float logP     = v[finalState]\n",
    "\n",
    "    # Now back trace through the model\n",
    "    currentState[L - 1] = finalState\n",
    "\n",
    "    for count in reversed(range(0, L - 1)):\n",
    "        currentState[count] = pTR[int(currentState[count + 1]), count + 1]\n",
    "        if currentState[count] == 0 & verbose == True:\n",
    "            print('stats:hmmviterbi:ZeroTransitionProbability', currentState[ count + 1 ])\n",
    "\n",
    "    return currentState, logP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x= hmmviterbi_vonmises(rawDecodeVec[:200, :], stateTrans, targLocs, B_cursorPos[:200, :], pStateStart,  4, adjust, False)[0]\n",
    "y= hmmviterbi_vonmises_parallel(rawDecodeVec[:200, :], stateTrans, targLocs, B_cursorPos[:200, :], pStateStart,  4, adjust, False)[0]\n",
    "diff = np.linalg.norm(x - y)\n",
    "\n",
    "print(\"Difference: \", diff)\n",
    "assert diff == 0, \"Error, outputs are different.\"\n",
    "%timeit hmmviterbi_vonmises(rawDecodeVec[:200, :], stateTrans, targLocs, B_cursorPos[:200, :], pStateStart, 4, adjust, verbose = False)\n",
    "%timeit hmmviterbi_vonmises_parallel(rawDecodeVec[:200, :], stateTrans, targLocs, B_cursorPos[:200, :], pStateStart, 4, adjust, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "@jit(nopython=True) \n",
    "def numba_sum(a, b):\n",
    "    x = a.shape[0]\n",
    "    D = np.empty((x, x), dtype=np.float64)\n",
    "    for i in range(x):\n",
    "        for j in range(x):\n",
    "            c = a[i, 0] + b[i, j]\n",
    "            D[i, j] = c[0]\n",
    "    return D\n",
    "    \n",
    "\n",
    "def EXP_hmmviterbi_vonmises(rawDecodeVec, stateTransitions, targLocs, cursorPos, pStateStart, vmKappa, adjustKappa = None, verbose = False):\n",
    "    '''Run viterbi algorithm to find most likely sequence of target states given the cursor position and decoder outputs. Inputs are:\n",
    "\n",
    "        rawDecodeVec (2D array)     - time x 2 array containing decoder outputs at each timepoint\n",
    "        stateTransitions (2D array) - transition probabilities; n_states x n_states\n",
    "        targLocs (2D array)         - n_states x 2 array containing corresponding target locations for each state\n",
    "        cursorPos (2D array)        - time x 2 array of cursor positions\n",
    "        pStateStart (vector)        - starting probabilities for each state \n",
    "        vmKappa (float)             - precision parameter for Von Mises observation model\n",
    "        adjustKappa (method)        - fxn for weighting kappa values; defaults to None\n",
    "        \n",
    "    NOTE:\n",
    "        - we could parallelize a lot of the below code (in the for loop) but it doesn't seem to result in substantial speed gains!\n",
    "            - around ~40 sec run vs 38 sec run during testing\n",
    "            - would need to fully cythonize to see substantial compute time decreases\n",
    "    '''\n",
    "    \n",
    "    start = time.time()\n",
    "    if adjustKappa is None:\n",
    "        def adjustKappa(dist):\n",
    "            return np.ones(dist.shape)\n",
    "\n",
    "    numStates    = len(stateTransitions)\n",
    "    L            = rawDecodeVec.shape[0]\n",
    "    currentState = np.zeros((L, ))\n",
    "    pTR          = np.zeros((numStates, L))\n",
    "\n",
    "    # work in log space to avoid numerical issues\n",
    "    logTR = np.log(stateTransitions)\n",
    "    tmpV  = np.zeros((numStates, numStates))\n",
    "    v     = np.log(pStateStart)\n",
    "    vOld  = np.copy(v)\n",
    "    print('Setup: ', time.time() - start)\n",
    "\n",
    "    # Precompute some values for speedup: \n",
    "    start             = time.time()\n",
    "    observedAngle_all = np.arctan2(rawDecodeVec[:, 1], rawDecodeVec[:, 0])\n",
    "    print('Angle precompute:', time.time() - start)\n",
    "\n",
    "    # loop through the model;  von mises emissions probabilities\n",
    "    T_expangle   = 0\n",
    "    T_kappadjust = 0\n",
    "    T_logprobs   = 0\n",
    "    T_updates    = 0\n",
    "    \n",
    "    start_forward = time.time()\n",
    "    for count in range(L):\n",
    "        # 1. compute distance from the cursor to each target, and expected angle for that target\n",
    "        start             = time.time()\n",
    "        tDists        = np.linalg.norm(targLocs - cursorPos[count, :], axis = 1)\n",
    "        normPosErr    = (targLocs - cursorPos[count, :]) / tDists[:, np.newaxis]\n",
    "        expectedAngle = np.arctan2(normPosErr[:, 1], normPosErr[:,0])\n",
    "        T_expangle += time.time() - start\n",
    "\n",
    "        # 2. compute expected precision based on the base kappa and distance to\n",
    "        # target (very close distances -> very large dispersion in expected angles)\n",
    "        start             = time.time()\n",
    "        vmKappa_adjusted = vmKappa * adjustKappa(tDists)\n",
    "        T_kappadjust += time.time() - start\n",
    "\n",
    "        # 3. compute VM probability densities\n",
    "        start             = time.time()\n",
    "        observedAngle = observedAngle_all[count]\n",
    "        vmProbLog     = (vmKappa_adjusted * np.cos(observedAngle - expectedAngle)) - np.log(2*np.pi* scipy.special.i0(vmKappa_adjusted))\n",
    "        T_logprobs += time.time() - start\n",
    "        \n",
    "        start         = time.time()\n",
    "        #tmpV          = vOld + logTR\n",
    "        tmpV          = numba_sum(vOld, logTR)\n",
    "        T_updates += time.time() - start\n",
    "        \n",
    "        maxIdx        = np.argmax(tmpV, axis = 1)\n",
    "        maxVal        = np.take_along_axis(tmpV, np.expand_dims(maxIdx, axis=-1), axis=-1).squeeze(axis=-1)\n",
    "        pTR[:,count]  = maxIdx\n",
    "        v             = vmProbLog + maxVal\n",
    "        vOld          = v\n",
    "        \n",
    "        \n",
    "    print(tmpV.shape)\n",
    "    print('Expected angle compute:', T_expangle)\n",
    "    print('Kappa adjust:', T_kappadjust)\n",
    "    print('posterior probs:', T_logprobs)\n",
    "    print('updates and storing: ', T_updates)\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    print('Forward loop: ', time.time() - start_forward)\n",
    "    # decide which of the final states is most probable\n",
    "    finalState = np.argmax(v)\n",
    "    logP       = v[finalState]\n",
    "\n",
    "    # Now back trace through the model\n",
    "    start_backward = time.time()\n",
    "    currentState[L - 1] = finalState\n",
    "    \n",
    "    for count in reversed(range(0, L - 1)):\n",
    "        currentState[count] = pTR[int(currentState[count + 1]), count + 1]\n",
    "        if currentState[count] == 0 & verbose == True:\n",
    "            print('stats:hmmviterbi:ZeroTransitionProbability', currentState[ count + 1 ])\n",
    "    print('Reverse loop: ', time.time() - start_backward)\n",
    "   # return currentState, logP\n",
    "    return tmpV, logTR\n",
    "\n",
    "def adjust(dist):\n",
    "    coef = 1 / (1 + np.exp(-1 * (dist - 70) * 0.5))\n",
    "    return coef \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup:  0.0\n",
      "Angle precompute: 0.0\n"
     ]
    },
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<built-in function getitem>) found for signature:\n \n >>> getitem(float64, Literal[int](0))\n \nThere are 22 candidate implementations:\n\u001b[1m      - Of which 22 did not match due to:\n      Overload of function 'getitem': File: <numerous>: Line N/A.\n        With argument(s): '(float64, int64)':\u001b[0m\n\u001b[1m       No match.\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of intrinsic-call at <ipython-input-21-d759067d843b> (12)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of static-get-item at <ipython-input-21-d759067d843b> (12)\u001b[0m\n\u001b[1m\nFile \"<ipython-input-21-d759067d843b>\", line 12:\u001b[0m\n\u001b[1mdef numba_sum(a, b):\n    <source elided>\n            c = a[i, 0] + b[i, j]\n\u001b[1m            D[i, j] = c[0]\n\u001b[0m            \u001b[1m^\u001b[0m\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-4bc90df538c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtmpV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogTR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEXP_hmmviterbi_vonmises\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawDecodeVec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstateTrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargLocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB_cursorPos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpStateStart\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madjust\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-d759067d843b>\u001b[0m in \u001b[0;36mEXP_hmmviterbi_vonmises\u001b[1;34m(rawDecodeVec, stateTransitions, targLocs, cursorPos, pStateStart, vmKappa, adjustKappa, verbose)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mstart\u001b[0m         \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m#tmpV          = vOld + logTR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mtmpV\u001b[0m          \u001b[1;33m=\u001b[0m \u001b[0mnumba_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvOld\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogTR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[0mT_updates\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\Nonstationarities\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    418\u001b[0m                 \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[0merror_rewrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'typing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[1;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\Nonstationarities\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[1;34m(e, issue_type)\u001b[0m\n\u001b[0;32m    359\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<built-in function getitem>) found for signature:\n \n >>> getitem(float64, Literal[int](0))\n \nThere are 22 candidate implementations:\n\u001b[1m      - Of which 22 did not match due to:\n      Overload of function 'getitem': File: <numerous>: Line N/A.\n        With argument(s): '(float64, int64)':\u001b[0m\n\u001b[1m       No match.\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of intrinsic-call at <ipython-input-21-d759067d843b> (12)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of static-get-item at <ipython-input-21-d759067d843b> (12)\u001b[0m\n\u001b[1m\nFile \"<ipython-input-21-d759067d843b>\", line 12:\u001b[0m\n\u001b[1mdef numba_sum(a, b):\n    <source elided>\n            c = a[i, 0] + b[i, j]\n\u001b[1m            D[i, j] = c[0]\n\u001b[0m            \u001b[1m^\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tmpV, logTR = EXP_hmmviterbi_vonmises(rawDecodeVec[:10000, :], stateTrans, targLocs, B_cursorPos[:10000, :], pStateStart,  4, adjust, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmpV:  (400, 400)\n",
      "logTR:  (400, 400)\n"
     ]
    }
   ],
   "source": [
    "print('tmpV: ', tmpV.shape)\n",
    "print('logTR: ', tmpV.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working -- dont touch\n",
    "\n",
    "%%cython \n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "@cython.boundscheck(True)#\n",
    "@cython.wraparound(False)\n",
    "def hmmviterbi_vonmises_parallel(np.ndarray[np.float_t, ndim=2] rawDecodeVec, np.ndarray[np.float_t, ndim=2] stateTransitions, np.ndarray[np.float_t, ndim=2] targLocs, \n",
    "                                 np.ndarray[np.float_t, ndim=2] cursorPos,  np.ndarray[np.float_t, ndim=2] pStateStart, float vmKappa, adjustKappa = None, bint verbose = False):\n",
    "    '''Run viterbi algorithm to find most likely sequence of target states given the cursor position and decoder outputs. Inputs are:\n",
    "\n",
    "        rawDecodeVec (2D array)     - time x 2 array containing decoder outputs at each timepoint\n",
    "        stateTransitions (2D array) - transition probabilities; n_states x n_states\n",
    "        targLocs (2D array)         - n_states x 2 array containing corresponding target locations for each state\n",
    "        cursorPos (2D array)        - time x 2 array of cursor positions\n",
    "        pStateStart (vector)        - starting probabilities for each state \n",
    "        vmKappa (float)             - precision parameter for Von Mises observation model\n",
    "        adjustKappa (method)        - fxn for weighting kappa values; defaults to None\n",
    "        \n",
    "    NOTE:\n",
    "        - we could parallelize a lot of the below code (in the for loop) but it doesn't seem to result in substantial speed gains!\n",
    "            - around ~40 sec run vs 38 sec run during testing\n",
    "            - would need to fully cythonize to see substantial compute time decreases\n",
    "    '''\n",
    "    cdef int numStates           = len(stateTransitions)\n",
    "    cdef int L                   = rawDecodeVec.shape[0]\n",
    "    cdef int[::1] currentState   = np.zeros((L, ), dtype= int)\n",
    "    \n",
    "    cdef int[:, ::1] pTR        = np.zeros((numStates, L), dtype= int)\n",
    "    cdef double[:, ::1] logTR   = np.log(stateTransitions)\n",
    "    cdef np.ndarray v           = np.log(pStateStart)\n",
    "    cdef np.ndarray vOld        = v\n",
    " \n",
    "\n",
    "    # declare variables used later:\n",
    "    cdef np.ndarray[np.float_t, ndim=2] tmpV\n",
    "    cdef np.intp_t count\n",
    "    cdef int[::1] maxIdx\n",
    "    cdef double[::1] maxVal\n",
    "    \n",
    "    # default kappa adjustment - none \n",
    "    if adjustKappa is None:\n",
    "        def adjustKappa(dist):\n",
    "            cdef np.ndarray adjusted = np.ones(dist.shape, dtype = np.float)\n",
    "            return adjusted\n",
    "\n",
    "    # Precompute some values for speedup: \n",
    "    cdef double[::1] observedAngle                       = np.arctan2(rawDecodeVec[:, 1], rawDecodeVec[:, 0])\n",
    "    cdef np.ndarray[np.float_t, ndim=2] tDists           = np.linalg.norm(targLocs - cursorPos[:, np.newaxis, :], axis = 2)\n",
    "    cdef np.ndarray[np.float_t, ndim=3] normPosErr       = (targLocs[:, np.newaxis] - cursorPos) / tDists.T[:, :, np.newaxis]\n",
    "    cdef np.ndarray[np.float_t, ndim=2] expectedAngle    = np.arctan2(normPosErr[:, :, 1], normPosErr[:, :, 0])\n",
    "    cdef np.ndarray[np.float_t, ndim=2] vmKappa_adjusted = vmKappa * adjustKappa(tDists)\n",
    "    cdef np.ndarray[np.float_t, ndim=2] vmProbLog        = (vmKappa_adjusted * np.cos(observedAngle - expectedAngle).T) - np.log(2 * np.pi * np.i0(vmKappa_adjusted))\n",
    "    #cdef np.ndarray[np.float_t, ndim=2] vmProbLog        = (vmKappa_adjusted * np.cos(observedAngle - expectedAngle).T) - np.log(2 * np.pi * scipy.special.i0(vmKappa_adjusted))\n",
    "\n",
    "    # loop through the model;  von mises emissions probabilities\n",
    "    for count in range(L):\n",
    "        tmpV          = vOld + logTR\n",
    "        maxIdx        = np.argmax(tmpV, axis = 1).astype('int')\n",
    "        maxVal        = np.take_along_axis(tmpV, np.expand_dims(maxIdx, axis=-1), axis=-1).squeeze(axis=-1)\n",
    "        \n",
    "        pTR[:,count] = maxIdx\n",
    "        v            = vmProbLog[count, :] + maxVal\n",
    "        vOld         = v\n",
    "    \n",
    "    # decide which of the final states is most probable\n",
    "    cdef int finalState = np.argmax(v)\n",
    "    cdef float logP     = v[finalState]\n",
    "\n",
    "    # Now back trace through the model\n",
    "    currentState[L - 1] = finalState\n",
    "\n",
    "    for count in reversed(range(0, L - 1)):\n",
    "        currentState[count] = pTR[int(currentState[count + 1]), count + 1]\n",
    "        if currentState[count] == 0 & verbose == True:\n",
    "            print('stats:hmmviterbi:ZeroTransitionProbability', currentState[ count + 1 ])\n",
    "\n",
    "    return currentState, logP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nonstationarities",
   "language": "python",
   "name": "nonstationarities"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
